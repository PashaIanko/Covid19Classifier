{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "bhoecUqzJvsh"
      },
      "outputs": [],
      "source": [
        "# MAIN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "0ol4IvhsbeFA"
      },
      "outputs": [],
      "source": [
        "# MAIN\n",
        "\n",
        "env = 'colab'  # 'colab' or 'pc'\n",
        "\n",
        "using_gpu = True  # True or False\n",
        "\n",
        "percentage = 0.08 # 0.99\n",
        "epoch_hyperparam = 500  # I use early stop\n",
        "train_percentage = percentage  # how much of train set we will use\n",
        "val_percentage = percentage\n",
        "test_percentage = percentage\n",
        "\n",
        "saving_models = True\n",
        "saving_train_times = True\n",
        "saving_histories = True\n",
        "n_trial = 1\n",
        "\n",
        "names = ['VGG19']  # , 'CNN']\n",
        "git_download_path = 'https://raw.githubusercontent.com/PashaIanko/Covid19Classifier/VGG19/'\n",
        "\n",
        "# Number of trial for this day (-> directory/24-01-22/trial-{n_trial}/ -- example of directories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfsyMy5yRWKF"
      },
      "source": [
        "# Packages & functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJq4oSfhRZY6",
        "outputId": "eda156a3-bf87-46df-8e1b-b4deb7d2b937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "def download_files(url_dict):\n",
        "    for file, url in url_dict.items():\n",
        "        print(f'Downloading {file}')\n",
        "        !wget -O {file} {url} {file}\n",
        "\n",
        "\n",
        "if env == 'colab':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    \n",
        "    files = [\n",
        "            'DataProperties.py',\n",
        "            'DatasetParameters.py',\n",
        "            'Preprocessing.py',\n",
        "            'PreprocessingParameters.py',\n",
        "            \n",
        "            'Model.py',\n",
        "            'BNModel.py',\n",
        "            'CNNModel.py',\n",
        "            'VGG19Model.py',\n",
        "            'VGG16Model.py',\n",
        "            'AlexNetModel.py',\n",
        "            'DropoutModel.py',\n",
        "            'InceptionModel.py',\n",
        "            'ResNetModel.py',\n",
        "\n",
        "            'Utils.py',\n",
        "            'ModelUtils.py',\n",
        "            'TimeCallBack.py'\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "2rAfLXFKykyQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[:3]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "s6vCIMfcyq-N"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[3:6]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "r6-Rf7MUzBxU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[6:]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "F1ZGnrMJRY1b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "c-oRA_bPUpOC"
      },
      "outputs": [],
      "source": [
        "# Models\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Conv2D as Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization as BatchNormalization\n",
        "from tensorflow.keras.layers import ReLU as ReLU\n",
        "from tensorflow.keras.layers import MaxPool2D as MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten as Flatten\n",
        "from tensorflow.keras.layers import Dense as Dense\n",
        "from tensorflow.keras.layers import Input as Input\n",
        "\n",
        "from os.path import isdir\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Plotting\n",
        "# import seaborn as sns\n",
        "\n",
        "# Utils\n",
        "import importlib\n",
        "from os.path import isdir\n",
        "# from datetime import date\n",
        "import pandas as pd\n",
        "\n",
        "# Dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "EOLlI5vMp3zH"
      },
      "outputs": [],
      "source": [
        "import DataProperties \n",
        "import PreprocessingParameters \n",
        "import Preprocessing\n",
        "import DatasetParameters\n",
        "import Utils\n",
        "import CNNModel\n",
        "import BNModel\n",
        "import ResNetModel\n",
        "import DropoutModel\n",
        "import InceptionModel\n",
        "import AlexNetModel\n",
        "import VGG19Model\n",
        "import VGG16Model\n",
        "import Model\n",
        "import ModelUtils\n",
        "import TimeCallBack\n",
        "\n",
        "def reload_all(modules_list):\n",
        "    for module in modules_list:\n",
        "        importlib.reload(module)\n",
        "\n",
        "reload_all(\n",
        "    [\n",
        "        DataProperties,\n",
        "        PreprocessingParameters,\n",
        "        DatasetParameters,\n",
        "        Utils,\n",
        "        Preprocessing,\n",
        "\n",
        "        Model,\n",
        "        CNNModel,\n",
        "        BNModel,\n",
        "        DropoutModel,\n",
        "        \n",
        "        VGG16Model,\n",
        "        ResNetModel,\n",
        "        InceptionModel,\n",
        "        ModelUtils,\n",
        "        TimeCallBack,\n",
        "        VGG19Model,\n",
        "        AlexNetModel\n",
        "    ]\n",
        ")\n",
        "\n",
        "from DataProperties import DataProperties\n",
        "from PreprocessingParameters import PreprocessingParameters\n",
        "from DatasetParameters import DatasetParameters\n",
        "from Utils import *\n",
        "from Preprocessing import *\n",
        "from CNNModel import CNNModel\n",
        "from BNModel import BNModel\n",
        "from DropoutModel import DropoutModel\n",
        "from VGG19Model import VGG19Model\n",
        "from ResNetModel import ResNetModel\n",
        "from InceptionModel import InceptionModel\n",
        "from ModelUtils import ModelUtils\n",
        "from TimeCallBack import TimeCallBack\n",
        "from AlexNetModel import AlexNetModel\n",
        "from VGG16Model import VGG16Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "X7b1_VvlHYqm"
      },
      "outputs": [],
      "source": [
        "DataProps = DataProperties(\n",
        "    environment = env,\n",
        "    n_trial = n_trial\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdFefXHCRONl"
      },
      "source": [
        "# Class balance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYflDFndXpq0"
      },
      "source": [
        "## Paths download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "yB4gIThHp3zR"
      },
      "outputs": [],
      "source": [
        "assert isdir(DataProps.train_data_path) == True\n",
        "assert isdir(DataProps.test_data_path) == True\n",
        "assert isdir(DataProps.val_data_path) == True\n",
        "assert isdir(DataProps.models_path) == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "R5w0G9ffc3x8"
      },
      "outputs": [],
      "source": [
        "train_files = calc_files(directory = DataProps.train_data_path)\n",
        "train_covid_files = calc_files(DataProps.train_covid_path)\n",
        "train_pn_files = calc_files(DataProps.train_pneumonia_path)\n",
        "train_healthy_files = calc_files(DataProps.train_healthy_path)\n",
        "\n",
        "assert train_files == (train_covid_files + train_pn_files + train_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "eiJ9GOvdc3x9"
      },
      "outputs": [],
      "source": [
        "val_files = calc_files(directory = DataProps.val_data_path)\n",
        "val_covid_files = calc_files(DataProps.val_covid_path)\n",
        "val_pn_files = calc_files(DataProps.val_pneumonia_path)\n",
        "val_healthy_files = calc_files(DataProps.val_healthy_path)\n",
        "\n",
        "assert val_files == (val_covid_files + val_pn_files + val_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "0z-s2L9Hc3x9"
      },
      "outputs": [],
      "source": [
        "test_files = calc_files(DataProps.test_data_path)\n",
        "test_covid_files = calc_files(DataProps.test_covid_path)\n",
        "test_pn_files = calc_files(DataProps.test_pneumonia_path)\n",
        "test_healthy_files = calc_files(DataProps.test_healthy_path)\n",
        "\n",
        "assert test_files == (test_covid_files + test_pn_files + test_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "vd5khqHOc3x9",
        "outputId": "5412e791-1b97-44c4-e925-72cc0a84a6c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'y')"
            ]
          },
          "metadata": {},
          "execution_count": 95
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x = ['T', 'V', 'Test']\n",
        "y = [train_files, val_files, test_files]\n",
        "\n",
        "fig, ax = plt.subplots()    \n",
        "width = 0.75 # the width of the bars \n",
        "ax.bar(x, y, width, color=\"blue\")\n",
        "plt.title('Data split')\n",
        "plt.xlabel('Data set')\n",
        "plt.ylabel('y') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6k8gAyybeFO",
        "outputId": "a09f3fe3-46a7-4fff-c4f2-505f626b7ff7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1067, 1067, 1067)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "train_covid_files, train_healthy_files, train_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3FufZoPbeFP",
        "outputId": "5a6528af-be6c-4dc6-a220-085440039926"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(229, 229, 229)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "val_covid_files, val_healthy_files, val_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1cbNyxfbeFP",
        "outputId": "a117a001-caa4-499c-e38f-b99591007609"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(229, 229, 229)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "test_covid_files, test_healthy_files, test_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jGO38VQbeFP",
        "outputId": "d0e0ad32-d212-4a7b-d5bd-e04f8cdf8a25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4575"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "train_files + val_files + test_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMTsTfy9dOH1"
      },
      "source": [
        "# Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJYeLGFxc_8h",
        "outputId": "48b89ed8-ae4a-4539-8d97-90a5e68a1305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target shape is (224, 224)\n"
          ]
        }
      ],
      "source": [
        "# Each model requires special input size -> need to check\n",
        "input_sizes = {\n",
        "    'VGG16': (224, 224),\n",
        "    'VGG19': (224, 224),\n",
        "    'AlexNet': (256, 256)\n",
        "}\n",
        "\n",
        "assert len(names) == 1\n",
        "if names[0] in list(input_sizes.keys()):\n",
        "    target_shape = input_sizes[names[0]]\n",
        "else:\n",
        "    target_shape = PreprocessingParameters.target_shape\n",
        "\n",
        "print(f'Target shape is {target_shape}')\n",
        "\n",
        "if names[0] == 'VGG16' or names[0] == 'VGG19':\n",
        "    assert target_shape == (224, 224)\n",
        "if names[0] == 'AlexNet':\n",
        "    assert target_shape == (256, 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD-sJtpibeFQ"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lSWgMs-p3zo",
        "outputId": "c4f958a3-0792-4514-c06d-fe9c79ef6d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 258 images belonging to 3 classes.\n",
            "Use 258 images for train\n"
          ]
        }
      ],
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "    # we use only a portion for train data (initially, to check if all works fine)\n",
        "    validation_split = 1 - train_percentage,  \n",
        "\n",
        "    # preprocessing\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    samplewise_center = DatasetParameters.samplewise_center,\n",
        "    featurewise_center = DatasetParameters.featurewise_center,\n",
        "    \n",
        "    # augmentation\n",
        "    width_shift_range = DatasetParameters.width_shift_range,\n",
        "    height_shift_range = DatasetParameters.height_shift_range,\n",
        "    rotation_range = DatasetParameters.rotation_range,\n",
        "    horizontal_flip = DatasetParameters.horizontal_flip,\n",
        "    vertical_flip = DatasetParameters.vertical_flip,\n",
        "    # brightness_range = [0.8, 1.0],\n",
        "    zoom_range = DatasetParameters.zoom_range\n",
        ")\n",
        "\n",
        "train_flow = train_generator.flow_from_directory(\n",
        "    directory = DataProps.train_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',  # 1D integer labels\n",
        "    batch_size = DatasetParameters.batch_size,\n",
        "    subset = 'training',\n",
        "    shuffle = DatasetParameters.shuffle_train,\n",
        "    seed = DatasetParameters.seed\n",
        ")\n",
        "print(f'Use {train_flow.n} images for train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW_Up6bkbeFR"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n98o85Jgc3x-",
        "outputId": "c98c94ad-e976-41c8-e43c-d0a861dd6b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 57 images belonging to 3 classes.\n",
            "Use 57 images for validation\n"
          ]
        }
      ],
      "source": [
        "val_generator = ImageDataGenerator(\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    validation_split = 1 - val_percentage\n",
        ")\n",
        "\n",
        "val_flow = train_generator.flow_from_directory(\n",
        "    directory = DataProps.val_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',  # 1D integer labels\n",
        "    batch_size = DatasetParameters.batch_size,\n",
        "    subset = 'training',  # yes, training - we use val_split of data \n",
        "    shuffle = DatasetParameters.shuffle_validation,\n",
        "    seed = DatasetParameters.seed\n",
        ")\n",
        "\n",
        "print(f'Use {val_flow.n} images for validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwXEti7RbeFR"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aESoE1FWp3zr",
        "outputId": "3c1d574e-fe50-47bb-abf8-09dceddb9f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 57 images belonging to 3 classes.\n",
            "Use 57 images for test\n"
          ]
        }
      ],
      "source": [
        "test_generator = ImageDataGenerator(\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    validation_split = 1 - test_percentage\n",
        ")\n",
        "\n",
        "test_flow = test_generator.flow_from_directory(\n",
        "    directory = DataProps.test_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',\n",
        "    shuffle = DatasetParameters.shuffle_test,\n",
        "    seed = DatasetParameters.seed,\n",
        "    batch_size = 1,\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "print(f'Use {test_flow.n} images for test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "gYAlvCLVp3zt"
      },
      "outputs": [],
      "source": [
        "assert train_flow.class_indices == test_flow.class_indices\n",
        "assert train_flow.class_indices == val_flow.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3WuMFeiabhG"
      },
      "source": [
        "# Visualizing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "xWs7ZSKVp3zu"
      },
      "outputs": [],
      "source": [
        "# how_many_to_show = 9\n",
        "# flow = train_flow\n",
        "# for _ in range(1):\n",
        "#     batch, labels = flow.next()\n",
        "#     print(batch.shape, np.max(batch))\n",
        "#     assert np.max(batch) <= 1.01\n",
        "#     assert np.min(batch) >= 0.0\n",
        "    \n",
        "#     visualize(\n",
        "#         batch, \n",
        "#         labels, \n",
        "#         how_many_to_show, \n",
        "#         class_indices = flow.class_indices,\n",
        "#         figsize=(10, 10)\n",
        "#     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOqcasA-beFS"
      },
      "source": [
        "# Fitting models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgxk5YIzbeFT"
      },
      "source": [
        "## Prepare steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61IBSOH_beFT",
        "outputId": "cbedf648-2cdb-45b7-bd0b-7db5dc5e3b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train steps: (258, 8)\n",
            "Val steps: (57, 1)\n"
          ]
        }
      ],
      "source": [
        "train_steps = train_flow.n // train_flow.batch_size\n",
        "validation_steps = val_flow.n // val_flow.batch_size\n",
        "test_steps = test_flow.n // test_flow.batch_size\n",
        "\n",
        "what_to_monitor = 'val_loss'\n",
        "validation_data = val_flow\n",
        "validation_steps = validation_steps\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor = what_to_monitor,\n",
        "    patience = 2,  # 3\n",
        "    mode = 'auto',\n",
        "    restore_best_weights = True,\n",
        "    min_delta = 0.0007\n",
        ")\n",
        "\n",
        "print(f'Train steps: {train_flow.n, train_steps}')\n",
        "print(f'Val steps: {val_flow.n, validation_steps}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dHNeeNkgehs"
      },
      "source": [
        "## FIXING BUG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "QUdE7eZ0gehs"
      },
      "outputs": [],
      "source": [
        "# model = tf.keras.models.Sequential()\n",
        "# model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(units=4096,activation=\"relu\"))\n",
        "# model.add(Dense(units=4096,activation=\"relu\"))\n",
        "# model.add(Dense(units=3, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "ozUQ_myygehs"
      },
      "outputs": [],
      "source": [
        "# model.compile(\n",
        "#     optimizer =  tf.keras.optimizers.Adam(learning_rate = 0.0001), #  tf.keras.optimizers.Adam(learning_rate = 0.001),  #  tf.keras.optimizers.Adam(learning_rate = 0.0001),  # tf.keras.optimizers.Adam(learning_rate = 0.01001), #  'adam',\n",
        "#     loss = 'sparse_categorical_crossentropy',  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "#     metrics = ['accuracy'] \n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "QzOmhL7Vgehs"
      },
      "outputs": [],
      "source": [
        "# model.fit(\n",
        "#     train_flow,\n",
        "#     steps_per_epoch = train_steps,\n",
        "#     validation_data = val_flow,\n",
        "#     validation_steps = validation_steps,\n",
        "#     epochs = 50\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "x1RWfdtzn91w"
      },
      "outputs": [],
      "source": [
        "# model = tf.keras.models.Sequential()\n",
        "\n",
        "# model.add(tf.keras.layers.Conv2D(64, kernel_size = (3,3), padding = 'same', activation = 'relu', input_shape = (224, 224, 3), kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.Conv2D(64, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv2D(128, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.Conv2D(128, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv2D(256, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.Conv2D(256, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.Conv2D(256, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.Conv2D(256, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
        "\n",
        "# model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "# model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
        "\n",
        "# model.add(tf.keras.layers.Flatten())\n",
        "# model.add(tf.keras.layers.Dense(4096, activation = 'relu'))\n",
        "# model.add(tf.keras.layers.Dropout(0.5))\n",
        "# model.add(tf.keras.layers.Dense(4096, activation = 'relu'))\n",
        "# model.add(tf.keras.layers.Dropout(0.5))\n",
        "# model.add(tf.keras.layers.Dense(3, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "P1DkT1f5n91w"
      },
      "outputs": [],
      "source": [
        "# model.compile(\n",
        "#     optimizer =  tf.keras.optimizers.Adam(learning_rate = 0.0001), #  tf.keras.optimizers.Adam(learning_rate = 0.001),  #  tf.keras.optimizers.Adam(learning_rate = 0.0001),  # tf.keras.optimizers.Adam(learning_rate = 0.01001), #  'adam',\n",
        "#     loss = 'sparse_categorical_crossentropy',  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "#     metrics = ['accuracy'] \n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "aJquwPDun91x"
      },
      "outputs": [],
      "source": [
        "# model.fit(\n",
        "#     train_flow,\n",
        "#     steps_per_epoch = train_steps,\n",
        "#     validation_data = val_flow,\n",
        "#     validation_steps = validation_steps,\n",
        "#     epochs = 50\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bnGCuV4uFk1"
      },
      "source": [
        "## Get_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "_mOKgACxtpUY"
      },
      "outputs": [],
      "source": [
        "def get_empty_models():\n",
        "    res = {\n",
        "        'CNN': CNNModel(name = 'CNN'),\n",
        "        'VGG19': VGG19Model(name = 'VGG19'),\n",
        "        'VGG16': VGG16Model(name = 'VGG16'),\n",
        "        'BN': BNModel(name = 'BN_CNN'),\n",
        "        'Dropout': DropoutModel(name = 'Dropout'),\n",
        "        'AlexNet': AlexNetModel(name = 'AlexNet'),\n",
        "        'Inception': InceptionModel(name = 'Inception'),\n",
        "        'ResNet': ResNetModel(name = 'ResNet')\n",
        "    }\n",
        "    return res\n",
        "    \n",
        "def construct_utils(model_name):\n",
        "    return ModelUtils(\n",
        "\n",
        "        model_params_dict = dict(**model_params),\n",
        "\n",
        "        checkpoint_params_dict = dict(\n",
        "            filepath = f'{DataProps.checkpoint_path}{model_name}/',\n",
        "            **checkpoint_params\n",
        "        ),\n",
        "\n",
        "        train_params_dict = dict(\n",
        "            **train_params\n",
        "        )\n",
        "    )\n",
        "\n",
        "def get_models(model_names):\n",
        "    empty_models = get_empty_models()\n",
        "    empty_model_names = list(empty_models.keys())\n",
        "    res = {}\n",
        "\n",
        "    for name in model_names:\n",
        "        assert name in empty_model_names\n",
        "        model = empty_models[name]\n",
        "        utils = construct_utils(name)\n",
        "\n",
        "        res.update(\n",
        "            {\n",
        "                name: {\n",
        "                    'model': model,\n",
        "                    'utils': utils\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "HXtgTpGFtpUZ"
      },
      "outputs": [],
      "source": [
        "train_params = dict(\n",
        "    train_flow = train_flow,\n",
        "    train_steps = train_steps,\n",
        "\n",
        "    val_flow = validation_data,\n",
        "    val_steps = validation_steps,\n",
        "\n",
        "    epochs = epoch_hyperparam  # DatasetParameters.epochs\n",
        ")\n",
        "\n",
        "model_params = dict(\n",
        "    optimizer =  tf.keras.optimizers.Adam(learning_rate = 0.0001), #  tf.keras.optimizers.SGD(learning_rate = 0.001),  #  tf.keras.optimizers.Adam(learning_rate = 0.0001),  # tf.keras.optimizers.Adam(learning_rate = 0.01001), #  'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "    metrics = ['acc'] \n",
        ")\n",
        "\n",
        "checkpoint_params = dict(\n",
        "    save_freq = 'epoch',\n",
        "    save_weights_only = True,\n",
        "    save_best_only = False,\n",
        "    verbose = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "AXoZOk-kbeFU"
      },
      "outputs": [],
      "source": [
        "models = get_models(names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "OWyWV1iXbeFT"
      },
      "outputs": [],
      "source": [
        "if using_gpu:\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name != '/device:GPU:0':\n",
        "        print(\n",
        "            '\\n\\nThis error most likely means that this notebook is not '\n",
        "            'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "            'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "        raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pihTRQph6Ngl"
      },
      "source": [
        "## Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22sYCf0BQEjY",
        "outputId": "1dfc8aaa-297e-484a-bdcb-95703f95204a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Printing summary of VGG19\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_64 (Conv2D)          (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 112, 112, 64)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_66 (Conv2D)          (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " conv2d_67 (Conv2D)          (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 56, 56, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_68 (Conv2D)          (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_69 (Conv2D)          (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_70 (Conv2D)          (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_71 (Conv2D)          (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 28, 28, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_72 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_73 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_74 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_75 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 14, 14, 512)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_76 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_77 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_78 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_79 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 7, 7, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 4096)              102764544 \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 3)                 12291     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 139,582,531\n",
            "Trainable params: 139,582,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "for name in names:\n",
        "    print(f'\\nPrinting summary of {name}')\n",
        "    print_summary(models, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW1tYvXtbeFT"
      },
      "source": [
        "## Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "bIlXdgwabeFU"
      },
      "outputs": [],
      "source": [
        "def fit_models(models_dict):\n",
        "\n",
        "    histories = {}\n",
        "    for model_name, parameters in models_dict.items():\n",
        "        \n",
        "        print(f'\\nFitting {model_name}')\n",
        "        model = parameters['model']\n",
        "        utils = parameters['utils']\n",
        "        \n",
        "        model.construct_model()\n",
        "        model.compile_model(**utils.model_params_dict)\n",
        "\n",
        "        checkpoint = tf.keras.callbacks.ModelCheckpoint(**utils.checkpoint_params_dict)\n",
        "\n",
        "        callbacks = [\n",
        "            early_stop,\n",
        "            checkpoint,\n",
        "            model.epoch_time_callback\n",
        "        ]\n",
        "\n",
        "        if using_gpu:\n",
        "            print(f'Fitting with GPU')\n",
        "            with tf.device(device_name):\n",
        "                history = fit_(\n",
        "                    **utils.train_params_dict,\n",
        "                    model = model.model,\n",
        "                    callbacks = callbacks\n",
        "                )\n",
        "        else:\n",
        "            print(f'Fitting without GPU')\n",
        "            history = fit_(\n",
        "                **utils.train_params_dict,\n",
        "                model = model.model,\n",
        "                callbacks = callbacks\n",
        "            )\n",
        "        histories[model_name] = history  \n",
        "\n",
        "        if saving_models:\n",
        "            save_dir = f'{DataProps.models_path}{model.name}/'\n",
        "            \n",
        "            if not(isdir(save_dir)):\n",
        "                os.mkdir(save_dir)\n",
        "            assert os.path.isdir(save_dir) == True\n",
        "            \n",
        "            print(f'saving model to dir: {save_dir}')\n",
        "            model.save_model(\n",
        "                dir = save_dir\n",
        "            )\n",
        "\n",
        "    if saving_histories:\n",
        "        print(f'Saving histories to {DataProps.histories_path}')\n",
        "        save_histories(histories, DataProps.histories_path)\n",
        "\n",
        "    \n",
        "    if saving_train_times:\n",
        "        save_times_dir = DataProps.models_path + 'training_time.csv'\n",
        "        print(f'Saving training times to {save_times_dir}')\n",
        "        save_train_times(\n",
        "            models_dict = models,\n",
        "            save_dir = save_times_dir\n",
        "        )\n",
        "\n",
        "    return histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "WcUrfNzJbeFU",
        "outputId": "56ab53f5-337f-4eeb-b6a7-128016790756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fitting VGG19\n",
            "Fitting with GPU\n",
            "Epoch 1/500\n",
            "1/8 [==>...........................] - ETA: 51s - loss: 1.4035 - acc: 0.3750"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-7ee078ef3e8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m histories = fit_models(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodels_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-118-75a9e644a547>\u001b[0m in \u001b[0;36mfit_models\u001b[0;34m(models_dict)\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_params_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 )\n\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Utils.py\u001b[0m in \u001b[0;36mfit_\u001b[0;34m(model, train_flow, train_steps, val_flow, val_steps, epochs, callbacks)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "histories = fit_models(\n",
        "    models_dict = models\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-GukL4IJvsz",
        "outputId": "95375596-f2aa-49e9-c002-f9e4b803f4ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'VGG19': <keras.callbacks.History at 0x7ff140100c90>}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "XIa-1ARBrcpz",
        "outputId": "79566e14-0e82-4043-b636-2858643a8d66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "681/681 [==============================] - 177s 258ms/step - loss: 0.3172 - acc: 0.8708\n"
          ]
        }
      ],
      "source": [
        "if 'VGG19' in names:\n",
        "    m = collect_metrics(\n",
        "        {'VGG': models['VGG19']['model']}, test_flow, test_steps\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6NiJZcErVAP",
        "outputId": "b60820f8-e7a3-4ca3-acc3-8158218d584f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "681/681 [==============================] - 174s 256ms/step - loss: 0.4739 - acc: 0.8311\n"
          ]
        }
      ],
      "source": [
        "if 'VGG16' in names:\n",
        "    m = collect_metrics(\n",
        "        {'VGG': models['VGG16']['model']}, test_flow, test_steps\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LbFq2gVPaJD",
        "outputId": "136b194f-50be-4c74-9e0c-a6ce63e52771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "681/681 [==============================] - 161s 236ms/step - loss: 0.3934 - accuracy: 0.8767\n"
          ]
        }
      ],
      "source": [
        "if 'AlexNet' in names:\n",
        "    m = collect_metrics(\n",
        "        {'Alex': models['AlexNet']['model']}, test_flow, test_steps\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ7N4rtPoQ7p",
        "outputId": "06d75ec2-94a9-422f-ce98-e81818161126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "276/276 [==============================] - 49s 180ms/step - loss: 1.4012 - accuracy: 0.3333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "if 'ResNet' in names:\n",
        "    m = collect_metrics(\n",
        "            {'ResNet': models['ResNet']['model']}, test_flow, test_steps\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIcHh1Lwi5TQ",
        "outputId": "29cfc143-513d-4d38-ab56-7a7d2e657bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69/69 [==============================] - 17s 254ms/step - loss: 1.0986 - accuracy: 0.3333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "if 'Inception' in names:\n",
        "    m = collect_metrics(\n",
        "            {'Inception': models['Inception']['model']}, test_flow, test_steps\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z44j222SB8t",
        "outputId": "16399cef-d398-4f53-9a51-2fb03c27aab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "681/681 [==============================] - 216s 318ms/step - loss: 0.7719 - acc: 0.8297\n"
          ]
        }
      ],
      "source": [
        "# To check if bugs\n",
        "if 'CNN' in names:\n",
        "    m = collect_metrics(\n",
        "        {'CNN': models['CNN']['model']}, test_flow, test_steps\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2enDTZdJvsz",
        "outputId": "900cbf06-23e1-4e0a-c1fe-08d522ebe2c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "138/138 [==============================] - 3s 21ms/step - loss: 0.6301 - acc: 0.6522\n"
          ]
        }
      ],
      "source": [
        "if 'Dropout' in names:\n",
        "    m = collect_metrics(\n",
        "            {'Dropout': models['Dropout']['model']}, test_flow, test_steps    \n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}