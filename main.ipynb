{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bhoecUqzJvsh"
      },
      "outputs": [],
      "source": [
        "# MAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0ol4IvhsbeFA"
      },
      "outputs": [],
      "source": [
        "# MAIN\n",
        "\n",
        "env = 'colab'  # 'colab' or 'pc'\n",
        "\n",
        "using_gpu = True  # True or False\n",
        "\n",
        "percentage = 0.2 # 0.99\n",
        "epoch_hyperparam = 500  # I use early stop\n",
        "train_percentage = percentage  # how much of train set we will use\n",
        "val_percentage = percentage\n",
        "test_percentage = percentage\n",
        "\n",
        "saving_models = True\n",
        "saving_train_times = True\n",
        "saving_histories = True\n",
        "n_trial = 1\n",
        "\n",
        "names = ['AlexNet']  # , 'CNN']\n",
        "git_download_path = 'https://raw.githubusercontent.com/PashaIanko/Covid19Classifier/fix_bug/'\n",
        "\n",
        "# Number of trial for this day (-> directory/24-01-22/trial-{n_trial}/ -- example of directories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfsyMy5yRWKF"
      },
      "source": [
        "# Packages & functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJq4oSfhRZY6",
        "outputId": "4a9c1556-66d9-4d65-ebc1-d449085520f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "def download_files(url_dict):\n",
        "    for file, url in url_dict.items():\n",
        "        print(f'Downloading {file}')\n",
        "        !wget -O {file} {url} {file}\n",
        "\n",
        "\n",
        "if env == 'colab':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    \n",
        "    files = [\n",
        "            'DataProperties.py',\n",
        "            'DatasetParameters.py',\n",
        "            'Preprocessing.py',\n",
        "            'PreprocessingParameters.py',\n",
        "            \n",
        "            'Model.py',\n",
        "            'BNModel.py',\n",
        "            'CNNModel.py',\n",
        "            'VGG19Model.py',\n",
        "            'VGG16Model.py',\n",
        "            'AlexNetModel.py',\n",
        "            'DropoutModel.py',\n",
        "            'InceptionModel.py',\n",
        "            'ResNetModel.py',\n",
        "\n",
        "            'Utils.py',\n",
        "            'ModelUtils.py',\n",
        "            'TimeCallBack.py'\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2rAfLXFKykyQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[:3]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s6vCIMfcyq-N"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[3:6]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "r6-Rf7MUzBxU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[6:]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F1ZGnrMJRY1b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c-oRA_bPUpOC"
      },
      "outputs": [],
      "source": [
        "# Models\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Conv2D as Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization as BatchNormalization\n",
        "from tensorflow.keras.layers import ReLU as ReLU\n",
        "from tensorflow.keras.layers import MaxPool2D as MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten as Flatten\n",
        "from tensorflow.keras.layers import Dense as Dense\n",
        "from tensorflow.keras.layers import Input as Input\n",
        "\n",
        "from os.path import isdir\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Plotting\n",
        "# import seaborn as sns\n",
        "\n",
        "# Utils\n",
        "import importlib\n",
        "from os.path import isdir\n",
        "# from datetime import date\n",
        "import pandas as pd\n",
        "\n",
        "# Dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EOLlI5vMp3zH"
      },
      "outputs": [],
      "source": [
        "import DataProperties \n",
        "import PreprocessingParameters \n",
        "import Preprocessing\n",
        "import DatasetParameters\n",
        "import Utils\n",
        "import CNNModel\n",
        "import BNModel\n",
        "import ResNetModel\n",
        "import DropoutModel\n",
        "import InceptionModel\n",
        "import AlexNetModel\n",
        "import VGG19Model\n",
        "import VGG16Model\n",
        "import Model\n",
        "import ModelUtils\n",
        "import TimeCallBack\n",
        "\n",
        "def reload_all(modules_list):\n",
        "    for module in modules_list:\n",
        "        importlib.reload(module)\n",
        "\n",
        "reload_all(\n",
        "    [\n",
        "        DataProperties,\n",
        "        PreprocessingParameters,\n",
        "        DatasetParameters,\n",
        "        Utils,\n",
        "        Preprocessing,\n",
        "\n",
        "        Model,\n",
        "        CNNModel,\n",
        "        BNModel,\n",
        "        DropoutModel,\n",
        "        \n",
        "        VGG16Model,\n",
        "        ResNetModel,\n",
        "        InceptionModel,\n",
        "        ModelUtils,\n",
        "        TimeCallBack,\n",
        "        VGG19Model,\n",
        "        AlexNetModel\n",
        "    ]\n",
        ")\n",
        "\n",
        "from DataProperties import DataProperties\n",
        "from PreprocessingParameters import PreprocessingParameters\n",
        "from DatasetParameters import DatasetParameters\n",
        "from Utils import *\n",
        "from Preprocessing import *\n",
        "from CNNModel import CNNModel\n",
        "from BNModel import BNModel\n",
        "from DropoutModel import DropoutModel\n",
        "from VGG19Model import VGG19Model\n",
        "from ResNetModel import ResNetModel\n",
        "from InceptionModel import InceptionModel\n",
        "from ModelUtils import ModelUtils\n",
        "from TimeCallBack import TimeCallBack\n",
        "from AlexNetModel import AlexNetModel\n",
        "from VGG16Model import VGG16Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "X7b1_VvlHYqm"
      },
      "outputs": [],
      "source": [
        "DataProps = DataProperties(\n",
        "    environment = env,\n",
        "    n_trial = n_trial\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdFefXHCRONl"
      },
      "source": [
        "# Class balance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYflDFndXpq0"
      },
      "source": [
        "## Paths download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yB4gIThHp3zR"
      },
      "outputs": [],
      "source": [
        "assert isdir(DataProps.train_data_path) == True\n",
        "assert isdir(DataProps.test_data_path) == True\n",
        "assert isdir(DataProps.val_data_path) == True\n",
        "assert isdir(DataProps.models_path) == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "R5w0G9ffc3x8"
      },
      "outputs": [],
      "source": [
        "train_files = calc_files(directory = DataProps.train_data_path)\n",
        "train_covid_files = calc_files(DataProps.train_covid_path)\n",
        "train_pn_files = calc_files(DataProps.train_pneumonia_path)\n",
        "train_healthy_files = calc_files(DataProps.train_healthy_path)\n",
        "\n",
        "assert train_files == (train_covid_files + train_pn_files + train_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eiJ9GOvdc3x9"
      },
      "outputs": [],
      "source": [
        "val_files = calc_files(directory = DataProps.val_data_path)\n",
        "val_covid_files = calc_files(DataProps.val_covid_path)\n",
        "val_pn_files = calc_files(DataProps.val_pneumonia_path)\n",
        "val_healthy_files = calc_files(DataProps.val_healthy_path)\n",
        "\n",
        "assert val_files == (val_covid_files + val_pn_files + val_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0z-s2L9Hc3x9"
      },
      "outputs": [],
      "source": [
        "test_files = calc_files(DataProps.test_data_path)\n",
        "test_covid_files = calc_files(DataProps.test_covid_path)\n",
        "test_pn_files = calc_files(DataProps.test_pneumonia_path)\n",
        "test_healthy_files = calc_files(DataProps.test_healthy_path)\n",
        "\n",
        "assert test_files == (test_covid_files + test_pn_files + test_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "vd5khqHOc3x9",
        "outputId": "728cc766-056d-40af-a067-9dc7048436f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'y')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x = ['T', 'V', 'Test']\n",
        "y = [train_files, val_files, test_files]\n",
        "\n",
        "fig, ax = plt.subplots()    \n",
        "width = 0.75 # the width of the bars \n",
        "ax.bar(x, y, width, color=\"blue\")\n",
        "plt.title('Data split')\n",
        "plt.xlabel('Data set')\n",
        "plt.ylabel('y') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6k8gAyybeFO",
        "outputId": "556d1ca2-2098-4a7a-ccf9-52128a9a9b48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1067, 1067, 1067)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "train_covid_files, train_healthy_files, train_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3FufZoPbeFP",
        "outputId": "1c0d8ef5-f624-4d26-c14d-dfe274394b48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(229, 229, 229)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "val_covid_files, val_healthy_files, val_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1cbNyxfbeFP",
        "outputId": "11ea3dcd-5c7d-4a80-cdd8-ddbd8ae76d84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(229, 229, 229)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "test_covid_files, test_healthy_files, test_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jGO38VQbeFP",
        "outputId": "c1aab18b-039d-4452-cb40-2a1a6742c039"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4575"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "train_files + val_files + test_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMTsTfy9dOH1"
      },
      "source": [
        "# Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJYeLGFxc_8h",
        "outputId": "828a52e2-3dcd-4cda-ff70-12e9b7ec2433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target shape is (256, 256)\n"
          ]
        }
      ],
      "source": [
        "# Each model requires special input size -> need to check\n",
        "input_sizes = {\n",
        "    'VGG16': (224, 224),\n",
        "    'AlexNet': (256, 256)\n",
        "}\n",
        "\n",
        "assert len(names) == 1\n",
        "if names[0] in list(input_sizes.keys()):\n",
        "    target_shape = input_sizes[names[0]]\n",
        "else:\n",
        "    target_shape = PreprocessingParameters.target_shape\n",
        "\n",
        "print(f'Target shape is {target_shape}')\n",
        "\n",
        "if names[0] == 'VGG16' or names[0] == 'VGG19':\n",
        "    assert target_shape == (224, 224)\n",
        "if names[0] == 'AlexNet':\n",
        "    assert target_shape == (256, 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD-sJtpibeFQ"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lSWgMs-p3zo",
        "outputId": "9b051fb2-8a54-4bd1-d4e1-f5bb7bdc4825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 642 images belonging to 3 classes.\n",
            "Use 642 images for train\n"
          ]
        }
      ],
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "    # we use only a portion for train data (initially, to check if all works fine)\n",
        "    validation_split = 1 - train_percentage,  \n",
        "\n",
        "    # preprocessing\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    samplewise_center = DatasetParameters.samplewise_center,\n",
        "    featurewise_center = DatasetParameters.featurewise_center,\n",
        "    \n",
        "    # augmentation\n",
        "    width_shift_range = DatasetParameters.width_shift_range,\n",
        "    height_shift_range = DatasetParameters.height_shift_range,\n",
        "    rotation_range = DatasetParameters.rotation_range,\n",
        "    horizontal_flip = DatasetParameters.horizontal_flip,\n",
        "    vertical_flip = DatasetParameters.vertical_flip,\n",
        "    # brightness_range = [0.8, 1.0],\n",
        "    zoom_range = DatasetParameters.zoom_range\n",
        ")\n",
        "\n",
        "train_flow = train_generator.flow_from_directory(\n",
        "    directory = DataProps.train_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',  # 1D integer labels\n",
        "    batch_size = DatasetParameters.batch_size,\n",
        "    subset = 'training',\n",
        "    shuffle = DatasetParameters.shuffle_train,\n",
        "    seed = DatasetParameters.seed\n",
        ")\n",
        "print(f'Use {train_flow.n} images for train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW_Up6bkbeFR"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n98o85Jgc3x-",
        "outputId": "2fd5cc40-33f9-4e45-f3d6-801134ed8b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 138 images belonging to 3 classes.\n",
            "Use 138 images for validation\n"
          ]
        }
      ],
      "source": [
        "val_generator = ImageDataGenerator(\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    validation_split = 1 - val_percentage\n",
        ")\n",
        "\n",
        "val_flow = train_generator.flow_from_directory(\n",
        "    directory = DataProps.val_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',  # 1D integer labels\n",
        "    batch_size = DatasetParameters.batch_size,\n",
        "    subset = 'training',  # yes, training - we use val_split of data \n",
        "    shuffle = DatasetParameters.shuffle_validation,\n",
        "    seed = DatasetParameters.seed\n",
        ")\n",
        "\n",
        "print(f'Use {val_flow.n} images for validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwXEti7RbeFR"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aESoE1FWp3zr",
        "outputId": "bdf7cf8c-1c68-4c1a-de67-95633c279ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 138 images belonging to 3 classes.\n",
            "Use 138 images for test\n"
          ]
        }
      ],
      "source": [
        "test_generator = ImageDataGenerator(\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    validation_split = 1 - test_percentage\n",
        ")\n",
        "\n",
        "test_flow = test_generator.flow_from_directory(\n",
        "    directory = DataProps.test_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',\n",
        "    shuffle = DatasetParameters.shuffle_test,\n",
        "    seed = DatasetParameters.seed,\n",
        "    batch_size = 1,\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "print(f'Use {test_flow.n} images for test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gYAlvCLVp3zt"
      },
      "outputs": [],
      "source": [
        "assert train_flow.class_indices == test_flow.class_indices\n",
        "assert train_flow.class_indices == val_flow.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3WuMFeiabhG"
      },
      "source": [
        "# Visualizing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "xWs7ZSKVp3zu",
        "outputId": "d1a53886-fabb-404e-be2f-676a944a1014"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-03a793166045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_flow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# how_many_to_show = 9\n",
        "# flow = train_flow\n",
        "# for _ in range(1):\n",
        "#     batch, labels = flow.next()\n",
        "#     print(batch.shape, np.max(batch))\n",
        "#     assert np.max(batch) <= 1.01\n",
        "#     assert np.min(batch) >= 0.0\n",
        "    \n",
        "#     visualize(\n",
        "#         batch, \n",
        "#         labels, \n",
        "#         how_many_to_show, \n",
        "#         class_indices = flow.class_indices,\n",
        "#         figsize=(10, 10)\n",
        "#     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOqcasA-beFS"
      },
      "source": [
        "# Fitting models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgxk5YIzbeFT"
      },
      "source": [
        "## Prepare steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61IBSOH_beFT",
        "outputId": "8f72dc0d-e0ea-4de9-8a71-16c29178083f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train steps: (642, 20)\n",
            "Val steps: (138, 4)\n"
          ]
        }
      ],
      "source": [
        "train_steps = train_flow.n // train_flow.batch_size\n",
        "validation_steps = val_flow.n // val_flow.batch_size\n",
        "test_steps = test_flow.n // test_flow.batch_size\n",
        "\n",
        "what_to_monitor = 'val_loss'\n",
        "validation_data = val_flow\n",
        "validation_steps = validation_steps\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor = what_to_monitor,\n",
        "    patience = 2,  # 3\n",
        "    mode = 'auto',\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "print(f'Train steps: {train_flow.n, train_steps}')\n",
        "print(f'Val steps: {val_flow.n, validation_steps}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEAZgqWi0_ub"
      },
      "source": [
        "## Fix bug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "b-0My8Gy0_uc"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bk8EEH6H0_ud"
      },
      "outputs": [],
      "source": [
        "class AlexNet(Sequential):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n",
        "                        padding= 'valid', activation= 'relu',\n",
        "                        input_shape= input_shape,\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None)) \n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
        "                        padding= 'same', activation= 'relu',\n",
        "                        kernel_initializer= 'he_normal'))\n",
        "\n",
        "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "                              padding= 'valid', data_format= None))\n",
        "\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(4096, activation= 'relu'))\n",
        "        self.add(Dense(4096, activation= 'relu'))\n",
        "        self.add(Dense(1000, activation= 'relu'))\n",
        "        self.add(Dense(num_classes, activation= 'softmax'))\n",
        "\n",
        "        # self.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "        #             loss='categorical_crossentropy',\n",
        "        #             metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "DyiVLDV-0_uf"
      },
      "outputs": [],
      "source": [
        "m = AlexNet((256, 256, 3), 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_d2K0XWG0_ug"
      },
      "outputs": [],
      "source": [
        "m.compile(\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.001),  # tf.keras.optimizers.Adam(learning_rate = 0.0001),  # tf.keras.optimizers.Adam(learning_rate = 0.01001), #  'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "    metrics = ['accuracy'] \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "VYvlk-0I0_uh",
        "outputId": "5242567d-b68f-474e-897a-48e4311fe2d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 142s 7s/step - loss: 1.1252 - accuracy: 0.4115 - val_loss: 0.9786 - val_accuracy: 0.5859\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 30s 2s/step - loss: 1.0372 - accuracy: 0.5311 - val_loss: 0.8972 - val_accuracy: 0.6250\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 30s 2s/step - loss: 0.9820 - accuracy: 0.5902 - val_loss: 0.8783 - val_accuracy: 0.6016\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 30s 2s/step - loss: 0.9327 - accuracy: 0.5705 - val_loss: 0.8689 - val_accuracy: 0.6016\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 30s 2s/step - loss: 0.9004 - accuracy: 0.5623 - val_loss: 0.8233 - val_accuracy: 0.6406\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 30s 1s/step - loss: 0.8461 - accuracy: 0.6066 - val_loss: 0.7750 - val_accuracy: 0.6875\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 30s 1s/step - loss: 0.8096 - accuracy: 0.6098 - val_loss: 0.7411 - val_accuracy: 0.6797\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - ETA: 0s - loss: 0.7956 - accuracy: 0.6426"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2b20f3baed4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;31m#epoch_hyperparam  # DatasetParameters.epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1261\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1264\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    947\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "m.fit(\n",
        "    train_flow,\n",
        "    steps_per_epoch = train_steps,\n",
        "\n",
        "    validation_data = validation_data,\n",
        "    validation_steps = validation_steps,\n",
        "\n",
        "    epochs = 50 #epoch_hyperparam  # DatasetParameters.epochs\n",
        ")\n",
        "\n",
        "# train_flow,\n",
        "\n",
        "\n",
        "#         steps_per_epoch = train_steps,\n",
        "        \n",
        "#         validation_data = val_flow,\n",
        "#         validation_steps = val_steps,\n",
        "\n",
        "#         epochs = epochs,\n",
        "#         callbacks = callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bnGCuV4uFk1"
      },
      "source": [
        "## Get_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mOKgACxtpUY"
      },
      "outputs": [],
      "source": [
        "def get_empty_models():\n",
        "    res = {\n",
        "        'CNN': CNNModel(name = 'CNN'),\n",
        "        'VGG19': VGG19Model(name = 'VGG19'),\n",
        "        'VGG16': VGG16Model(name = 'VGG16'),\n",
        "        'BN': BNModel(name = 'BN_CNN'),\n",
        "        'Dropout': DropoutModel(name = 'Dropout'),\n",
        "        'AlexNet': AlexNetModel(name = 'AlexNet'),\n",
        "        'Inception': InceptionModel(name = 'Inception'),\n",
        "        'ResNet': ResNetModel(name = 'ResNet')\n",
        "    }\n",
        "    return res\n",
        "    \n",
        "def construct_utils(model_name):\n",
        "    return ModelUtils(\n",
        "\n",
        "        model_params_dict = dict(**model_params),\n",
        "\n",
        "        checkpoint_params_dict = dict(\n",
        "            filepath = f'{DataProps.checkpoint_path}{model_name}/',\n",
        "            **checkpoint_params\n",
        "        ),\n",
        "\n",
        "        train_params_dict = dict(\n",
        "            **train_params\n",
        "        )\n",
        "    )\n",
        "\n",
        "def get_models(model_names):\n",
        "    empty_models = get_empty_models()\n",
        "    empty_model_names = list(empty_models.keys())\n",
        "    res = {}\n",
        "\n",
        "    for name in model_names:\n",
        "        assert name in empty_model_names\n",
        "        model = empty_models[name]\n",
        "        utils = construct_utils(name)\n",
        "\n",
        "        res.update(\n",
        "            {\n",
        "                name: {\n",
        "                    'model': model,\n",
        "                    'utils': utils\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXtgTpGFtpUZ"
      },
      "outputs": [],
      "source": [
        "train_params = dict(\n",
        "    train_flow = train_flow,\n",
        "    train_steps = train_steps,\n",
        "\n",
        "    val_flow = validation_data,\n",
        "    val_steps = validation_steps,\n",
        "\n",
        "    epochs = epoch_hyperparam  # DatasetParameters.epochs\n",
        ")\n",
        "\n",
        "model_params = dict(\n",
        "    optimizer =  tf.keras.optimizers.Adam(learning_rate = 0.0001),  # tf.keras.optimizers.Adam(learning_rate = 0.01001), #  'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "    metrics = ['accuracy'] \n",
        ")\n",
        "\n",
        "checkpoint_params = dict(\n",
        "    save_freq = 'epoch',\n",
        "    save_weights_only = True,\n",
        "    save_best_only = False,\n",
        "    verbose = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXoZOk-kbeFU"
      },
      "outputs": [],
      "source": [
        "models = get_models(names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWyWV1iXbeFT"
      },
      "outputs": [],
      "source": [
        "if using_gpu:\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name != '/device:GPU:0':\n",
        "        print(\n",
        "            '\\n\\nThis error most likely means that this notebook is not '\n",
        "            'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "            'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "        raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pihTRQph6Ngl"
      },
      "source": [
        "## Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22sYCf0BQEjY",
        "outputId": "535dfd42-2baa-442d-b8b4-a8b125e4bd0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Printing summary of AlexNet\n",
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 64, 64, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_40 (Activation)   (None, 64, 64, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 31, 31, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 8, 8, 256)         614656    \n",
            "_________________________________________________________________\n",
            "activation_41 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 1, 1, 384)         885120    \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 1, 1, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 1, 1, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 1, 1, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 1, 1, 256)         884992    \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 3)                 12291     \n",
            "=================================================================\n",
            "Total params: 21,593,475\n",
            "Trainable params: 21,593,475\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "for name in names:\n",
        "    print(f'\\nPrinting summary of {name}')\n",
        "    print_summary(models, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW1tYvXtbeFT"
      },
      "source": [
        "## Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIlXdgwabeFU"
      },
      "outputs": [],
      "source": [
        "def fit_models(models_dict):\n",
        "\n",
        "    histories = {}\n",
        "    for model_name, parameters in models_dict.items():\n",
        "        \n",
        "        print(f'\\nFitting {model_name}')\n",
        "        model = parameters['model']\n",
        "        utils = parameters['utils']\n",
        "        \n",
        "        model.construct_model()\n",
        "        model.compile_model(**utils.model_params_dict)\n",
        "\n",
        "        checkpoint = tf.keras.callbacks.ModelCheckpoint(**utils.checkpoint_params_dict)\n",
        "\n",
        "        callbacks = [\n",
        "            early_stop,\n",
        "            checkpoint,\n",
        "            model.epoch_time_callback\n",
        "        ]\n",
        "\n",
        "        if using_gpu:\n",
        "            print(f'Fitting with GPU')\n",
        "            with tf.device(device_name):\n",
        "                history = fit_(\n",
        "                    **utils.train_params_dict,\n",
        "                    model = model.model,\n",
        "                    callbacks = callbacks\n",
        "                )\n",
        "        else:\n",
        "            print(f'Fitting without GPU')\n",
        "            history = fit_(\n",
        "                **utils.train_params_dict,\n",
        "                model = model.model,\n",
        "                callbacks = callbacks\n",
        "            )\n",
        "        histories[model_name] = history  \n",
        "\n",
        "        if saving_models:\n",
        "            save_dir = f'{DataProps.models_path}{model.name}/'\n",
        "            \n",
        "            if not(isdir(save_dir)):\n",
        "                os.mkdir(save_dir)\n",
        "            assert os.path.isdir(save_dir) == True\n",
        "            \n",
        "            print(f'saving model to dir: {save_dir}')\n",
        "            model.save_model(\n",
        "                dir = save_dir\n",
        "            )\n",
        "\n",
        "    if saving_histories:\n",
        "        print(f'Saving histories to {DataProps.histories_path}')\n",
        "        save_histories(histories, DataProps.histories_path)\n",
        "\n",
        "    \n",
        "    if saving_train_times:\n",
        "        save_times_dir = DataProps.models_path + 'training_time.csv'\n",
        "        print(f'Saving training times to {save_times_dir}')\n",
        "        save_train_times(\n",
        "            models_dict = models,\n",
        "            save_dir = save_times_dir\n",
        "        )\n",
        "\n",
        "    return histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "WcUrfNzJbeFU",
        "outputId": "c2551943-758f-4037-d454-75d071b88472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fitting AlexNet\n",
            "Fitting without GPU\n",
            "ERROR:tensorflow:Couldn't match files for checkpoint C:/Users/79137/Pasha/2. UNIPD/HDA/Project/Checkpoints/2022-01-31/AlexNet\\.\n",
            "Epoch 1/500\n",
            "7/8 [=========================>....] - ETA: 2s - loss: 2269759849.2641 - acc: 0.2732\n",
            "Epoch 00001: saving model to C:/Users/79137/Pasha/2. UNIPD/HDA/Project/Checkpoints/2022-01-31/AlexNet/\n",
            "8/8 [==============================] - 26s 3s/step - loss: 2014480549.4063 - acc: 0.2832 - val_loss: 182702272.0000 - val_acc: 0.5938\n",
            "Epoch 2/500\n",
            "7/8 [=========================>....] - ETA: 2s - loss: 76994111.2321 - acc: 0.2887"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9980\\2620315080.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m histories = fit_models(\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodels_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m )\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9980\\3203908886.py\u001b[0m in \u001b[0;36mfit_models\u001b[1;34m(models_dict)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_params_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             )\n\u001b[0;32m     36\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\79137\\Pasha\\2. UNIPD\\HDA\\Project\\Code\\Covid19Classifier\\Utils.py\u001b[0m in \u001b[0;36mfit_\u001b[1;34m(model, train_flow, train_steps, val_flow, val_steps, epochs, callbacks)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m     )\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    674\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager_dataset_or_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m       \u001b[1;31m# Make sure that y, sample_weights, validation_split are not passed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    320\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m           \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m           steps_name='validation_steps')\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m       \u001b[0mbatch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[1;34m(generator, mode)\u001b[0m\n\u001b[0;32m    360\u001b[0m   \u001b[1;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    777\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "histories = fit_models(\n",
        "    models_dict = models\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-GukL4IJvsz",
        "outputId": "df260732-c969-407c-9058-505bb7de57cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Inception': <keras.callbacks.History at 0x7f73fa0929d0>}"
            ]
          },
          "execution_count": 270,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ7N4rtPoQ7p",
        "outputId": "06d75ec2-94a9-422f-ce98-e81818161126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "276/276 [==============================] - 49s 180ms/step - loss: 1.4012 - accuracy: 0.3333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "if 'ResNet' in names:\n",
        "    m = collect_metrics(\n",
        "            {'ResNet': models['ResNet']['model']}, test_flow, test_steps\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIcHh1Lwi5TQ",
        "outputId": "29cfc143-513d-4d38-ab56-7a7d2e657bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69/69 [==============================] - 17s 254ms/step - loss: 1.0986 - accuracy: 0.3333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "if 'Inception' in names:\n",
        "    m = collect_metrics(\n",
        "            {'Inception': models['Inception']['model']}, test_flow, test_steps\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z44j222SB8t",
        "outputId": "16399cef-d398-4f53-9a51-2fb03c27aab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "681/681 [==============================] - 216s 318ms/step - loss: 0.7719 - acc: 0.8297\n"
          ]
        }
      ],
      "source": [
        "# To check if bugs\n",
        "if 'CNN' in names:\n",
        "    m = collect_metrics(\n",
        "        {'CNN': models['CNN']['model']}, test_flow, test_steps\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2enDTZdJvsz",
        "outputId": "900cbf06-23e1-4e0a-c1fe-08d522ebe2c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "138/138 [==============================] - 3s 21ms/step - loss: 0.6301 - acc: 0.6522\n"
          ]
        }
      ],
      "source": [
        "if 'Dropout' in names:\n",
        "    m = collect_metrics(\n",
        "            {'Dropout': models['Dropout']['model']}, test_flow, test_steps    \n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}