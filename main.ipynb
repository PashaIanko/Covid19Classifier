{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "bhoecUqzJvsh"
      },
      "outputs": [],
      "source": [
        "# MAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "0ol4IvhsbeFA"
      },
      "outputs": [],
      "source": [
        "# MAIN\n",
        "\n",
        "env = 'pc'  # 'colab' or 'pc'\n",
        "\n",
        "using_gpu = False  # True or False\n",
        "\n",
        "percentage = 0.06 # 0.99\n",
        "epoch_hyperparam = 500  # I use early stop\n",
        "train_percentage = percentage  # how much of train set we will use\n",
        "val_percentage = percentage\n",
        "test_percentage = percentage\n",
        "\n",
        "saving_models = True\n",
        "saving_train_times = True\n",
        "saving_histories = True\n",
        "n_trial = 1\n",
        "\n",
        "names = ['VGG16']  # , 'CNN']\n",
        "git_download_path = 'https://raw.githubusercontent.com/PashaIanko/Covid19Classifier/main/'\n",
        "\n",
        "# Number of trial for this day (-> directory/24-01-22/trial-{n_trial}/ -- example of directories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfsyMy5yRWKF"
      },
      "source": [
        "# Packages & functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJq4oSfhRZY6",
        "outputId": "7bf090da-62a2-4ca9-d0d6-ff7eaaecedda"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "def download_files(url_dict):\n",
        "    for file, url in url_dict.items():\n",
        "        print(f'Downloading {file}')\n",
        "        !wget -O {file} {url} {file}\n",
        "\n",
        "\n",
        "if env == 'colab':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    \n",
        "    files = [\n",
        "            'DataProperties.py',\n",
        "            'DatasetParameters.py',\n",
        "            'Preprocessing.py',\n",
        "            'PreprocessingParameters.py',\n",
        "            \n",
        "            'Model.py',\n",
        "            'BNModel.py',\n",
        "            'CNNModel.py',\n",
        "            'VGG19Model.py',\n",
        "            'VGG16Model.py',\n",
        "            'AlexNetModel.py',\n",
        "            'DropoutModel.py',\n",
        "            'InceptionModel.py',\n",
        "            'ResNetModel.py',\n",
        "\n",
        "            'Utils.py',\n",
        "            'ModelUtils.py',\n",
        "            'TimeCallBack.py'\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "2rAfLXFKykyQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[:3]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "s6vCIMfcyq-N"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[3:6]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "r6-Rf7MUzBxU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[6:]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "F1ZGnrMJRY1b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "c-oRA_bPUpOC"
      },
      "outputs": [],
      "source": [
        "# Models\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Conv2D as Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization as BatchNormalization\n",
        "from tensorflow.keras.layers import ReLU as ReLU\n",
        "from tensorflow.keras.layers import MaxPool2D as MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten as Flatten\n",
        "from tensorflow.keras.layers import Dense as Dense\n",
        "from tensorflow.keras.layers import Input as Input\n",
        "\n",
        "from os.path import isdir\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Plotting\n",
        "# import seaborn as sns\n",
        "\n",
        "# Utils\n",
        "import importlib\n",
        "from os.path import isdir\n",
        "# from datetime import date\n",
        "import pandas as pd\n",
        "\n",
        "# Dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "EOLlI5vMp3zH"
      },
      "outputs": [],
      "source": [
        "import DataProperties \n",
        "import PreprocessingParameters \n",
        "import Preprocessing\n",
        "import DatasetParameters\n",
        "import Utils\n",
        "import CNNModel\n",
        "import BNModel\n",
        "import ResNetModel\n",
        "import DropoutModel\n",
        "import InceptionModel\n",
        "import AlexNetModel\n",
        "import VGG19Model\n",
        "import VGG16Model\n",
        "import Model\n",
        "import ModelUtils\n",
        "import TimeCallBack\n",
        "\n",
        "def reload_all(modules_list):\n",
        "    for module in modules_list:\n",
        "        importlib.reload(module)\n",
        "\n",
        "reload_all(\n",
        "    [\n",
        "        DataProperties,\n",
        "        PreprocessingParameters,\n",
        "        DatasetParameters,\n",
        "        Utils,\n",
        "        Preprocessing,\n",
        "\n",
        "        Model,\n",
        "        CNNModel,\n",
        "        BNModel,\n",
        "        DropoutModel,\n",
        "        \n",
        "        VGG16Model,\n",
        "        ResNetModel,\n",
        "        InceptionModel,\n",
        "        ModelUtils,\n",
        "        TimeCallBack,\n",
        "        VGG19Model,\n",
        "        AlexNetModel\n",
        "    ]\n",
        ")\n",
        "\n",
        "from DataProperties import DataProperties\n",
        "from PreprocessingParameters import PreprocessingParameters\n",
        "from DatasetParameters import DatasetParameters\n",
        "from Utils import *\n",
        "from Preprocessing import *\n",
        "from CNNModel import CNNModel\n",
        "from BNModel import BNModel\n",
        "from DropoutModel import DropoutModel\n",
        "from VGG19Model import VGG19Model\n",
        "from ResNetModel import ResNetModel\n",
        "from InceptionModel import InceptionModel\n",
        "from ModelUtils import ModelUtils\n",
        "from TimeCallBack import TimeCallBack\n",
        "from AlexNetModel import AlexNetModel\n",
        "from VGG16Model import VGG16Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "X7b1_VvlHYqm"
      },
      "outputs": [],
      "source": [
        "DataProps = DataProperties(\n",
        "    environment = env,\n",
        "    n_trial = n_trial\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdFefXHCRONl"
      },
      "source": [
        "# Class balance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYflDFndXpq0"
      },
      "source": [
        "## Paths download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "yB4gIThHp3zR"
      },
      "outputs": [],
      "source": [
        "assert isdir(DataProps.train_data_path) == True\n",
        "assert isdir(DataProps.test_data_path) == True\n",
        "assert isdir(DataProps.val_data_path) == True\n",
        "assert isdir(DataProps.models_path) == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "R5w0G9ffc3x8"
      },
      "outputs": [],
      "source": [
        "train_files = calc_files(directory = DataProps.train_data_path)\n",
        "train_covid_files = calc_files(DataProps.train_covid_path)\n",
        "train_pn_files = calc_files(DataProps.train_pneumonia_path)\n",
        "train_healthy_files = calc_files(DataProps.train_healthy_path)\n",
        "\n",
        "assert train_files == (train_covid_files + train_pn_files + train_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "eiJ9GOvdc3x9"
      },
      "outputs": [],
      "source": [
        "val_files = calc_files(directory = DataProps.val_data_path)\n",
        "val_covid_files = calc_files(DataProps.val_covid_path)\n",
        "val_pn_files = calc_files(DataProps.val_pneumonia_path)\n",
        "val_healthy_files = calc_files(DataProps.val_healthy_path)\n",
        "\n",
        "assert val_files == (val_covid_files + val_pn_files + val_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "0z-s2L9Hc3x9"
      },
      "outputs": [],
      "source": [
        "test_files = calc_files(DataProps.test_data_path)\n",
        "test_covid_files = calc_files(DataProps.test_covid_path)\n",
        "test_pn_files = calc_files(DataProps.test_pneumonia_path)\n",
        "test_healthy_files = calc_files(DataProps.test_healthy_path)\n",
        "\n",
        "assert test_files == (test_covid_files + test_pn_files + test_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vd5khqHOc3x9",
        "outputId": "6f0c7392-53f1-4773-fa07-9cf5d61936dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'y')"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = ['T', 'V', 'Test']\n",
        "y = [train_files, val_files, test_files]\n",
        "\n",
        "fig, ax = plt.subplots()    \n",
        "width = 0.75 # the width of the bars \n",
        "ax.bar(x, y, width, color=\"blue\")\n",
        "plt.title('Data split')\n",
        "plt.xlabel('Data set')\n",
        "plt.ylabel('y') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6k8gAyybeFO",
        "outputId": "82baffd5-1cdf-485e-d8b9-9ecf87ad2e53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1067, 1067, 1067)"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_covid_files, train_healthy_files, train_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3FufZoPbeFP",
        "outputId": "65e78ab5-377e-4e4f-9d46-4d90263c5805"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(229, 229, 229)"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_covid_files, val_healthy_files, val_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1cbNyxfbeFP",
        "outputId": "b8c2cef8-1fe1-4d73-f89a-7f4aeefdcbe7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(229, 229, 229)"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_covid_files, test_healthy_files, test_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jGO38VQbeFP",
        "outputId": "a2c3abce-6175-4c96-fd5d-123d588d5d3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4575"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_files + val_files + test_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMTsTfy9dOH1"
      },
      "source": [
        "# Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJYeLGFxc_8h",
        "outputId": "5731e35a-1f77-4876-f0b4-2d838f574ed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target shape is (224, 224)\n"
          ]
        }
      ],
      "source": [
        "# Each model requires special input size -> need to check\n",
        "input_sizes = {\n",
        "    'VGG16': (224, 224),\n",
        "    'AlexNet': (256, 256)\n",
        "}\n",
        "\n",
        "assert len(names) == 1\n",
        "if names[0] in list(input_sizes.keys()):\n",
        "    target_shape = input_sizes[names[0]]\n",
        "else:\n",
        "    target_shape = PreprocessingParameters.target_shape\n",
        "\n",
        "print(f'Target shape is {target_shape}')\n",
        "\n",
        "if names[0] == 'VGG16' or names[0] == 'VGG19':\n",
        "    assert target_shape == (224, 224)\n",
        "if names[0] == 'AlexNet':\n",
        "    assert target_shape == (256, 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD-sJtpibeFQ"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lSWgMs-p3zo",
        "outputId": "ad0c957c-26b3-496e-9e27-0ce15e068e16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 195 images belonging to 3 classes.\n",
            "Use 195 images for train\n"
          ]
        }
      ],
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "    # we use only a portion for train data (initially, to check if all works fine)\n",
        "    validation_split = 1 - train_percentage,  \n",
        "\n",
        "    # preprocessing\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    samplewise_center = DatasetParameters.samplewise_center,\n",
        "    featurewise_center = DatasetParameters.featurewise_center,\n",
        "    \n",
        "    # augmentation\n",
        "    width_shift_range = DatasetParameters.width_shift_range,\n",
        "    height_shift_range = DatasetParameters.height_shift_range,\n",
        "    rotation_range = DatasetParameters.rotation_range,\n",
        "    horizontal_flip = DatasetParameters.horizontal_flip,\n",
        "    vertical_flip = DatasetParameters.vertical_flip,\n",
        "    # brightness_range = [0.8, 1.0],\n",
        "    zoom_range = DatasetParameters.zoom_range\n",
        ")\n",
        "\n",
        "train_flow = train_generator.flow_from_directory(\n",
        "    directory = DataProps.train_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',  # 1D integer labels\n",
        "    batch_size = DatasetParameters.batch_size,\n",
        "    subset = 'training',\n",
        "    shuffle = DatasetParameters.shuffle_train,\n",
        "    seed = DatasetParameters.seed\n",
        ")\n",
        "print(f'Use {train_flow.n} images for train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW_Up6bkbeFR"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n98o85Jgc3x-",
        "outputId": "0a2415b3-0d38-43d4-d864-46189c65d08a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 42 images belonging to 3 classes.\n",
            "Use 42 images for validation\n"
          ]
        }
      ],
      "source": [
        "val_generator = ImageDataGenerator(\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    validation_split = 1 - val_percentage\n",
        ")\n",
        "\n",
        "val_flow = train_generator.flow_from_directory(\n",
        "    directory = DataProps.val_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',  # 1D integer labels\n",
        "    batch_size = DatasetParameters.batch_size,\n",
        "    subset = 'training',  # yes, training - we use val_split of data \n",
        "    shuffle = DatasetParameters.shuffle_validation,\n",
        "    seed = DatasetParameters.seed\n",
        ")\n",
        "\n",
        "print(f'Use {val_flow.n} images for validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwXEti7RbeFR"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aESoE1FWp3zr",
        "outputId": "0a37a07a-6bdf-4d15-b2f3-9a2facb7e511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 42 images belonging to 3 classes.\n",
            "Use 42 images for test\n"
          ]
        }
      ],
      "source": [
        "test_generator = ImageDataGenerator(\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    validation_split = 1 - test_percentage\n",
        ")\n",
        "\n",
        "test_flow = test_generator.flow_from_directory(\n",
        "    directory = DataProps.test_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',\n",
        "    shuffle = DatasetParameters.shuffle_test,\n",
        "    seed = DatasetParameters.seed,\n",
        "    batch_size = 1,\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "print(f'Use {test_flow.n} images for test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "gYAlvCLVp3zt"
      },
      "outputs": [],
      "source": [
        "assert train_flow.class_indices == test_flow.class_indices\n",
        "assert train_flow.class_indices == val_flow.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3WuMFeiabhG"
      },
      "source": [
        "# Visualizing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "xWs7ZSKVp3zu"
      },
      "outputs": [],
      "source": [
        "# how_many_to_show = 9\n",
        "# flow = train_flow\n",
        "# for _ in range(1):\n",
        "#     batch, labels = flow.next()\n",
        "#     print(batch.shape, np.max(batch))\n",
        "#     assert np.max(batch) <= 1.01\n",
        "#     assert np.min(batch) >= 0.0\n",
        "    \n",
        "#     visualize(\n",
        "#         batch, \n",
        "#         labels, \n",
        "#         how_many_to_show, \n",
        "#         class_indices = flow.class_indices,\n",
        "#         figsize=(10, 10)\n",
        "#     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOqcasA-beFS"
      },
      "source": [
        "# Fitting models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgxk5YIzbeFT"
      },
      "source": [
        "## Prepare steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61IBSOH_beFT",
        "outputId": "aaa0638e-4ef5-4324-c398-c0c9ef376363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train steps: (195, 6)\n",
            "Val steps: (42, 1)\n"
          ]
        }
      ],
      "source": [
        "train_steps = train_flow.n // train_flow.batch_size\n",
        "validation_steps = val_flow.n // val_flow.batch_size\n",
        "test_steps = test_flow.n // test_flow.batch_size\n",
        "\n",
        "what_to_monitor = 'val_loss'\n",
        "validation_data = val_flow\n",
        "validation_steps = validation_steps\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor = what_to_monitor,\n",
        "    patience = 2,  # 3\n",
        "    mode = 'auto',\n",
        "    restore_best_weights = True,\n",
        "    min_delta = 0.0007\n",
        ")\n",
        "\n",
        "print(f'Train steps: {train_flow.n, train_steps}')\n",
        "print(f'Val steps: {val_flow.n, validation_steps}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FIXING BUG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=3, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer =  tf.keras.optimizers.Adam(learning_rate = 0.001),  #  tf.keras.optimizers.Adam(learning_rate = 0.0001),  # tf.keras.optimizers.Adam(learning_rate = 0.01001), #  'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "    metrics = ['accuracy'] \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - 95s 16s/step - loss: 1618.8939 - acc: 0.3681 - val_loss: 1.0933 - val_acc: 0.4375\n",
            "Epoch 2/50\n",
            "2/6 [=========>....................] - ETA: 1:10 - loss: 1.0974 - acc: 0.3750"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26716\\4301279.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_flow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m )\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    674\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager_dataset_or_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m       \u001b[1;31m# Make sure that y, sample_weights, validation_split are not passed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(\n",
        "    train_flow,\n",
        "    steps_per_epoch = train_steps,\n",
        "    validation_data = val_flow,\n",
        "    validation_steps = validation_steps,\n",
        "    epochs = 50\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bnGCuV4uFk1"
      },
      "source": [
        "## Get_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "_mOKgACxtpUY"
      },
      "outputs": [],
      "source": [
        "def get_empty_models():\n",
        "    res = {\n",
        "        'CNN': CNNModel(name = 'CNN'),\n",
        "        'VGG19': VGG19Model(name = 'VGG19'),\n",
        "        'VGG16': VGG16Model(name = 'VGG16'),\n",
        "        'BN': BNModel(name = 'BN_CNN'),\n",
        "        'Dropout': DropoutModel(name = 'Dropout'),\n",
        "        'AlexNet': AlexNetModel(name = 'AlexNet'),\n",
        "        'Inception': InceptionModel(name = 'Inception'),\n",
        "        'ResNet': ResNetModel(name = 'ResNet')\n",
        "    }\n",
        "    return res\n",
        "    \n",
        "def construct_utils(model_name):\n",
        "    return ModelUtils(\n",
        "\n",
        "        model_params_dict = dict(**model_params),\n",
        "\n",
        "        checkpoint_params_dict = dict(\n",
        "            filepath = f'{DataProps.checkpoint_path}{model_name}/',\n",
        "            **checkpoint_params\n",
        "        ),\n",
        "\n",
        "        train_params_dict = dict(\n",
        "            **train_params\n",
        "        )\n",
        "    )\n",
        "\n",
        "def get_models(model_names):\n",
        "    empty_models = get_empty_models()\n",
        "    empty_model_names = list(empty_models.keys())\n",
        "    res = {}\n",
        "\n",
        "    for name in model_names:\n",
        "        assert name in empty_model_names\n",
        "        model = empty_models[name]\n",
        "        utils = construct_utils(name)\n",
        "\n",
        "        res.update(\n",
        "            {\n",
        "                name: {\n",
        "                    'model': model,\n",
        "                    'utils': utils\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "HXtgTpGFtpUZ"
      },
      "outputs": [],
      "source": [
        "train_params = dict(\n",
        "    train_flow = train_flow,\n",
        "    train_steps = train_steps,\n",
        "\n",
        "    val_flow = validation_data,\n",
        "    val_steps = validation_steps,\n",
        "\n",
        "    epochs = epoch_hyperparam  # DatasetParameters.epochs\n",
        ")\n",
        "\n",
        "model_params = dict(\n",
        "    optimizer =  tf.keras.optimizers.SGD(learning_rate = 0.001),  #  tf.keras.optimizers.Adam(learning_rate = 0.0001),  # tf.keras.optimizers.Adam(learning_rate = 0.01001), #  'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "    metrics = ['accuracy'] \n",
        ")\n",
        "\n",
        "checkpoint_params = dict(\n",
        "    save_freq = 'epoch',\n",
        "    save_weights_only = True,\n",
        "    save_best_only = False,\n",
        "    verbose = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "AXoZOk-kbeFU"
      },
      "outputs": [],
      "source": [
        "models = get_models(names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "OWyWV1iXbeFT"
      },
      "outputs": [],
      "source": [
        "if using_gpu:\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name != '/device:GPU:0':\n",
        "        print(\n",
        "            '\\n\\nThis error most likely means that this notebook is not '\n",
        "            'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "            'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "        raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pihTRQph6Ngl"
      },
      "source": [
        "## Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22sYCf0BQEjY",
        "outputId": "c59f332e-0a88-49d9-dfb2-5ec5b4672f5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Printing summary of VGG16\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 12291     \n",
            "=================================================================\n",
            "Total params: 134,272,835\n",
            "Trainable params: 134,272,835\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "for name in names:\n",
        "    print(f'\\nPrinting summary of {name}')\n",
        "    print_summary(models, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW1tYvXtbeFT"
      },
      "source": [
        "## Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "bIlXdgwabeFU"
      },
      "outputs": [],
      "source": [
        "def fit_models(models_dict):\n",
        "\n",
        "    histories = {}\n",
        "    for model_name, parameters in models_dict.items():\n",
        "        \n",
        "        print(f'\\nFitting {model_name}')\n",
        "        model = parameters['model']\n",
        "        utils = parameters['utils']\n",
        "        \n",
        "        model.construct_model()\n",
        "        model.compile_model(**utils.model_params_dict)\n",
        "\n",
        "        checkpoint = tf.keras.callbacks.ModelCheckpoint(**utils.checkpoint_params_dict)\n",
        "\n",
        "        callbacks = [\n",
        "            early_stop,\n",
        "            checkpoint,\n",
        "            model.epoch_time_callback\n",
        "        ]\n",
        "\n",
        "        if using_gpu:\n",
        "            print(f'Fitting with GPU')\n",
        "            with tf.device(device_name):\n",
        "                history = fit_(\n",
        "                    **utils.train_params_dict,\n",
        "                    model = model.model,\n",
        "                    callbacks = callbacks\n",
        "                )\n",
        "        else:\n",
        "            print(f'Fitting without GPU')\n",
        "            history = fit_(\n",
        "                **utils.train_params_dict,\n",
        "                model = model.model,\n",
        "                callbacks = callbacks\n",
        "            )\n",
        "        histories[model_name] = history  \n",
        "\n",
        "        if saving_models:\n",
        "            save_dir = f'{DataProps.models_path}{model.name}/'\n",
        "            \n",
        "            if not(isdir(save_dir)):\n",
        "                os.mkdir(save_dir)\n",
        "            assert os.path.isdir(save_dir) == True\n",
        "            \n",
        "            print(f'saving model to dir: {save_dir}')\n",
        "            model.save_model(\n",
        "                dir = save_dir\n",
        "            )\n",
        "\n",
        "    if saving_histories:\n",
        "        print(f'Saving histories to {DataProps.histories_path}')\n",
        "        save_histories(histories, DataProps.histories_path)\n",
        "\n",
        "    \n",
        "    if saving_train_times:\n",
        "        save_times_dir = DataProps.models_path + 'training_time.csv'\n",
        "        print(f'Saving training times to {save_times_dir}')\n",
        "        save_train_times(\n",
        "            models_dict = models,\n",
        "            save_dir = save_times_dir\n",
        "        )\n",
        "\n",
        "    return histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WcUrfNzJbeFU",
        "outputId": "667ed0dd-d079-4209-bd28-7c2fb54beb0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fitting VGG16\n",
            "Fitting without GPU\n",
            "Epoch 1/500\n",
            " 9/10 [==========================>...] - ETA: 13s - loss: 1.0985 - acc: 0.3074\n",
            "Epoch 00001: saving model to C:/Users/79137/Pasha/2. UNIPD/HDA/Project/Checkpoints/2022-01-31/VGG16/\n",
            "10/10 [==============================] - 148s 15s/step - loss: 1.0985 - acc: 0.3218 - val_loss: 1.0985 - val_acc: 0.3594\n",
            "Epoch 2/500\n",
            " 6/10 [=================>............] - ETA: 1:03 - loss: 1.0985 - acc: 0.3490"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26716\\2620315080.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m histories = fit_models(\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodels_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m )\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26716\\3203908886.py\u001b[0m in \u001b[0;36mfit_models\u001b[1;34m(models_dict)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_params_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             )\n\u001b[0;32m     36\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\79137\\Pasha\\2. UNIPD\\HDA\\Project\\Code\\Covid19Classifier\\Utils.py\u001b[0m in \u001b[0;36mfit_\u001b[1;34m(model, train_flow, train_steps, val_flow, val_steps, epochs, callbacks)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m     )\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    674\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager_dataset_or_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m       \u001b[1;31m# Make sure that y, sample_weights, validation_split are not passed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "histories = fit_models(\n",
        "    models_dict = models\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-GukL4IJvsz",
        "outputId": "7608f219-4a9c-42ed-b5e0-f8691c6d1e11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'AlexNet': <keras.callbacks.History at 0x7ff9bc849550>}"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LbFq2gVPaJD",
        "outputId": "136b194f-50be-4c74-9e0c-a6ce63e52771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "681/681 [==============================] - 161s 236ms/step - loss: 0.3934 - accuracy: 0.8767\n"
          ]
        }
      ],
      "source": [
        "if 'AlexNet' in names:\n",
        "    m = collect_metrics(\n",
        "        {'Alex': models['AlexNet']['model']}, test_flow, test_steps\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ7N4rtPoQ7p",
        "outputId": "06d75ec2-94a9-422f-ce98-e81818161126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "276/276 [==============================] - 49s 180ms/step - loss: 1.4012 - accuracy: 0.3333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "if 'ResNet' in names:\n",
        "    m = collect_metrics(\n",
        "            {'ResNet': models['ResNet']['model']}, test_flow, test_steps\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIcHh1Lwi5TQ",
        "outputId": "29cfc143-513d-4d38-ab56-7a7d2e657bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69/69 [==============================] - 17s 254ms/step - loss: 1.0986 - accuracy: 0.3333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "if 'Inception' in names:\n",
        "    m = collect_metrics(\n",
        "            {'Inception': models['Inception']['model']}, test_flow, test_steps\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z44j222SB8t",
        "outputId": "16399cef-d398-4f53-9a51-2fb03c27aab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "681/681 [==============================] - 216s 318ms/step - loss: 0.7719 - acc: 0.8297\n"
          ]
        }
      ],
      "source": [
        "# To check if bugs\n",
        "if 'CNN' in names:\n",
        "    m = collect_metrics(\n",
        "        {'CNN': models['CNN']['model']}, test_flow, test_steps\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2enDTZdJvsz",
        "outputId": "900cbf06-23e1-4e0a-c1fe-08d522ebe2c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "138/138 [==============================] - 3s 21ms/step - loss: 0.6301 - acc: 0.6522\n"
          ]
        }
      ],
      "source": [
        "if 'Dropout' in names:\n",
        "    m = collect_metrics(\n",
        "            {'Dropout': models['Dropout']['model']}, test_flow, test_steps    \n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
