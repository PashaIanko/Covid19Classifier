{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "id": "bhoecUqzJvsh"
      },
      "outputs": [],
      "source": [
        "# MAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {
        "id": "0ol4IvhsbeFA"
      },
      "outputs": [],
      "source": [
        "# MAIN\n",
        "\n",
        "env = 'pc'  # 'colab' or 'pc'\n",
        "\n",
        "using_gpu = False  # True or False\n",
        "\n",
        "percentage = 0.1 # 0.99\n",
        "epoch_hyperparam = 500  # I use early stop\n",
        "train_percentage = percentage  # how much of train set we will use\n",
        "val_percentage = percentage\n",
        "test_percentage = percentage\n",
        "\n",
        "saving_models = True\n",
        "saving_train_times = True\n",
        "saving_histories = True\n",
        "n_trial = 1\n",
        "\n",
        "names = ['AlexNet']  # , 'CNN']\n",
        "git_download_path = 'https://raw.githubusercontent.com/PashaIanko/Covid19Classifier/fix_bug/'\n",
        "\n",
        "# Number of trial for this day (-> directory/24-01-22/trial-{n_trial}/ -- example of directories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfsyMy5yRWKF"
      },
      "source": [
        "# Packages & functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJq4oSfhRZY6",
        "outputId": "4a9c1556-66d9-4d65-ebc1-d449085520f7"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "def download_files(url_dict):\n",
        "    for file, url in url_dict.items():\n",
        "        print(f'Downloading {file}')\n",
        "        !wget -O {file} {url} {file}\n",
        "\n",
        "\n",
        "if env == 'colab':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    \n",
        "    files = [\n",
        "            'DataProperties.py',\n",
        "            'DatasetParameters.py',\n",
        "            'Preprocessing.py',\n",
        "            'PreprocessingParameters.py',\n",
        "            \n",
        "            'Model.py',\n",
        "            'BNModel.py',\n",
        "            'CNNModel.py',\n",
        "            'VGG19Model.py',\n",
        "            'VGG16Model.py',\n",
        "            'AlexNetModel.py',\n",
        "            'DropoutModel.py',\n",
        "            'InceptionModel.py',\n",
        "            'ResNetModel.py',\n",
        "\n",
        "            'Utils.py',\n",
        "            'ModelUtils.py',\n",
        "            'TimeCallBack.py'\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "id": "2rAfLXFKykyQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[:3]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {
        "id": "s6vCIMfcyq-N"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[3:6]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "id": "r6-Rf7MUzBxU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[6:]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {
        "id": "F1ZGnrMJRY1b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "id": "c-oRA_bPUpOC"
      },
      "outputs": [],
      "source": [
        "# Models\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Conv2D as Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization as BatchNormalization\n",
        "from tensorflow.keras.layers import ReLU as ReLU\n",
        "from tensorflow.keras.layers import MaxPool2D as MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten as Flatten\n",
        "from tensorflow.keras.layers import Dense as Dense\n",
        "from tensorflow.keras.layers import Input as Input\n",
        "\n",
        "from os.path import isdir\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Plotting\n",
        "# import seaborn as sns\n",
        "\n",
        "# Utils\n",
        "import importlib\n",
        "from os.path import isdir\n",
        "# from datetime import date\n",
        "import pandas as pd\n",
        "\n",
        "# Dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {
        "id": "EOLlI5vMp3zH"
      },
      "outputs": [],
      "source": [
        "import DataProperties \n",
        "import PreprocessingParameters \n",
        "import Preprocessing\n",
        "import DatasetParameters\n",
        "import Utils\n",
        "import CNNModel\n",
        "import BNModel\n",
        "import ResNetModel\n",
        "import DropoutModel\n",
        "import InceptionModel\n",
        "import AlexNetModel\n",
        "import VGG19Model\n",
        "import VGG16Model\n",
        "import Model\n",
        "import ModelUtils\n",
        "import TimeCallBack\n",
        "\n",
        "def reload_all(modules_list):\n",
        "    for module in modules_list:\n",
        "        importlib.reload(module)\n",
        "\n",
        "reload_all(\n",
        "    [\n",
        "        DataProperties,\n",
        "        PreprocessingParameters,\n",
        "        DatasetParameters,\n",
        "        Utils,\n",
        "        Preprocessing,\n",
        "\n",
        "        Model,\n",
        "        CNNModel,\n",
        "        BNModel,\n",
        "        DropoutModel,\n",
        "        \n",
        "        VGG16Model,\n",
        "        ResNetModel,\n",
        "        InceptionModel,\n",
        "        ModelUtils,\n",
        "        TimeCallBack,\n",
        "        VGG19Model,\n",
        "        AlexNetModel\n",
        "    ]\n",
        ")\n",
        "\n",
        "from DataProperties import DataProperties\n",
        "from PreprocessingParameters import PreprocessingParameters\n",
        "from DatasetParameters import DatasetParameters\n",
        "from Utils import *\n",
        "from Preprocessing import *\n",
        "from CNNModel import CNNModel\n",
        "from BNModel import BNModel\n",
        "from DropoutModel import DropoutModel\n",
        "from VGG19Model import VGG19Model\n",
        "from ResNetModel import ResNetModel\n",
        "from InceptionModel import InceptionModel\n",
        "from ModelUtils import ModelUtils\n",
        "from TimeCallBack import TimeCallBack\n",
        "from AlexNetModel import AlexNetModel\n",
        "from VGG16Model import VGG16Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "id": "X7b1_VvlHYqm"
      },
      "outputs": [],
      "source": [
        "DataProps = DataProperties(\n",
        "    environment = env,\n",
        "    n_trial = n_trial\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdFefXHCRONl"
      },
      "source": [
        "# Class balance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYflDFndXpq0"
      },
      "source": [
        "## Paths download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {
        "id": "yB4gIThHp3zR"
      },
      "outputs": [],
      "source": [
        "assert isdir(DataProps.train_data_path) == True\n",
        "assert isdir(DataProps.test_data_path) == True\n",
        "assert isdir(DataProps.val_data_path) == True\n",
        "assert isdir(DataProps.models_path) == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "id": "R5w0G9ffc3x8"
      },
      "outputs": [],
      "source": [
        "train_files = calc_files(directory = DataProps.train_data_path)\n",
        "train_covid_files = calc_files(DataProps.train_covid_path)\n",
        "train_pn_files = calc_files(DataProps.train_pneumonia_path)\n",
        "train_healthy_files = calc_files(DataProps.train_healthy_path)\n",
        "\n",
        "assert train_files == (train_covid_files + train_pn_files + train_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {
        "id": "eiJ9GOvdc3x9"
      },
      "outputs": [],
      "source": [
        "val_files = calc_files(directory = DataProps.val_data_path)\n",
        "val_covid_files = calc_files(DataProps.val_covid_path)\n",
        "val_pn_files = calc_files(DataProps.val_pneumonia_path)\n",
        "val_healthy_files = calc_files(DataProps.val_healthy_path)\n",
        "\n",
        "assert val_files == (val_covid_files + val_pn_files + val_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {
        "id": "0z-s2L9Hc3x9"
      },
      "outputs": [],
      "source": [
        "test_files = calc_files(DataProps.test_data_path)\n",
        "test_covid_files = calc_files(DataProps.test_covid_path)\n",
        "test_pn_files = calc_files(DataProps.test_pneumonia_path)\n",
        "test_healthy_files = calc_files(DataProps.test_healthy_path)\n",
        "\n",
        "assert test_files == (test_covid_files + test_pn_files + test_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "vd5khqHOc3x9",
        "outputId": "728cc766-056d-40af-a067-9dc7048436f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'y')"
            ]
          },
          "execution_count": 314,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = ['T', 'V', 'Test']\n",
        "y = [train_files, val_files, test_files]\n",
        "\n",
        "fig, ax = plt.subplots()    \n",
        "width = 0.75 # the width of the bars \n",
        "ax.bar(x, y, width, color=\"blue\")\n",
        "plt.title('Data split')\n",
        "plt.xlabel('Data set')\n",
        "plt.ylabel('y') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6k8gAyybeFO",
        "outputId": "556d1ca2-2098-4a7a-ccf9-52128a9a9b48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1067, 1067, 1067)"
            ]
          },
          "execution_count": 315,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_covid_files, train_healthy_files, train_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3FufZoPbeFP",
        "outputId": "1c0d8ef5-f624-4d26-c14d-dfe274394b48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(229, 229, 229)"
            ]
          },
          "execution_count": 316,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_covid_files, val_healthy_files, val_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1cbNyxfbeFP",
        "outputId": "11ea3dcd-5c7d-4a80-cdd8-ddbd8ae76d84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(229, 229, 229)"
            ]
          },
          "execution_count": 317,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_covid_files, test_healthy_files, test_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jGO38VQbeFP",
        "outputId": "c1aab18b-039d-4452-cb40-2a1a6742c039"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4575"
            ]
          },
          "execution_count": 318,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_files + val_files + test_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMTsTfy9dOH1"
      },
      "source": [
        "# Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJYeLGFxc_8h",
        "outputId": "828a52e2-3dcd-4cda-ff70-12e9b7ec2433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target shape is (256, 256)\n"
          ]
        }
      ],
      "source": [
        "# Each model requires special input size -> need to check\n",
        "input_sizes = {\n",
        "    'VGG16': (224, 224),\n",
        "    'AlexNet': (256, 256)\n",
        "}\n",
        "\n",
        "assert len(names) == 1\n",
        "if names[0] in list(input_sizes.keys()):\n",
        "    target_shape = input_sizes[names[0]]\n",
        "else:\n",
        "    target_shape = PreprocessingParameters.target_shape\n",
        "\n",
        "print(f'Target shape is {target_shape}')\n",
        "\n",
        "if names[0] == 'VGG16' or names[0] == 'VGG19':\n",
        "    assert target_shape == (224, 224)\n",
        "if names[0] == 'AlexNet':\n",
        "    assert target_shape == (256, 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD-sJtpibeFQ"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 320,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lSWgMs-p3zo",
        "outputId": "9b051fb2-8a54-4bd1-d4e1-f5bb7bdc4825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 321 images belonging to 3 classes.\n",
            "Use 321 images for train\n"
          ]
        }
      ],
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "    # we use only a portion for train data (initially, to check if all works fine)\n",
        "    validation_split = 1 - train_percentage,  \n",
        "\n",
        "    # preprocessing\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    samplewise_center = DatasetParameters.samplewise_center,\n",
        "    featurewise_center = DatasetParameters.featurewise_center,\n",
        "    \n",
        "    # augmentation\n",
        "    width_shift_range = DatasetParameters.width_shift_range,\n",
        "    height_shift_range = DatasetParameters.height_shift_range,\n",
        "    rotation_range = DatasetParameters.rotation_range,\n",
        "    horizontal_flip = DatasetParameters.horizontal_flip,\n",
        "    vertical_flip = DatasetParameters.vertical_flip,\n",
        "    # brightness_range = [0.8, 1.0],\n",
        "    zoom_range = DatasetParameters.zoom_range\n",
        ")\n",
        "\n",
        "train_flow = train_generator.flow_from_directory(\n",
        "    directory = DataProps.train_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',  # 1D integer labels\n",
        "    batch_size = DatasetParameters.batch_size,\n",
        "    subset = 'training',\n",
        "    shuffle = DatasetParameters.shuffle_train,\n",
        "    seed = DatasetParameters.seed\n",
        ")\n",
        "print(f'Use {train_flow.n} images for train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW_Up6bkbeFR"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 321,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n98o85Jgc3x-",
        "outputId": "2fd5cc40-33f9-4e45-f3d6-801134ed8b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 69 images belonging to 3 classes.\n",
            "Use 69 images for validation\n"
          ]
        }
      ],
      "source": [
        "val_generator = ImageDataGenerator(\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    validation_split = 1 - val_percentage\n",
        ")\n",
        "\n",
        "val_flow = train_generator.flow_from_directory(\n",
        "    directory = DataProps.val_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',  # 1D integer labels\n",
        "    batch_size = DatasetParameters.batch_size,\n",
        "    subset = 'training',  # yes, training - we use val_split of data \n",
        "    shuffle = DatasetParameters.shuffle_validation,\n",
        "    seed = DatasetParameters.seed\n",
        ")\n",
        "\n",
        "print(f'Use {val_flow.n} images for validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwXEti7RbeFR"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 322,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aESoE1FWp3zr",
        "outputId": "bdf7cf8c-1c68-4c1a-de67-95633c279ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 69 images belonging to 3 classes.\n",
            "Use 69 images for test\n"
          ]
        }
      ],
      "source": [
        "test_generator = ImageDataGenerator(\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    validation_split = 1 - test_percentage\n",
        ")\n",
        "\n",
        "test_flow = test_generator.flow_from_directory(\n",
        "    directory = DataProps.test_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',\n",
        "    shuffle = DatasetParameters.shuffle_test,\n",
        "    seed = DatasetParameters.seed,\n",
        "    batch_size = 1,\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "print(f'Use {test_flow.n} images for test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 323,
      "metadata": {
        "id": "gYAlvCLVp3zt"
      },
      "outputs": [],
      "source": [
        "assert train_flow.class_indices == test_flow.class_indices\n",
        "assert train_flow.class_indices == val_flow.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3WuMFeiabhG"
      },
      "source": [
        "# Visualizing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 324,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "xWs7ZSKVp3zu",
        "outputId": "d1a53886-fabb-404e-be2f-676a944a1014"
      },
      "outputs": [],
      "source": [
        "# how_many_to_show = 9\n",
        "# flow = train_flow\n",
        "# for _ in range(1):\n",
        "#     batch, labels = flow.next()\n",
        "#     print(batch.shape, np.max(batch))\n",
        "#     assert np.max(batch) <= 1.01\n",
        "#     assert np.min(batch) >= 0.0\n",
        "    \n",
        "#     visualize(\n",
        "#         batch, \n",
        "#         labels, \n",
        "#         how_many_to_show, \n",
        "#         class_indices = flow.class_indices,\n",
        "#         figsize=(10, 10)\n",
        "#     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOqcasA-beFS"
      },
      "source": [
        "# Fitting models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgxk5YIzbeFT"
      },
      "source": [
        "## Prepare steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61IBSOH_beFT",
        "outputId": "8f72dc0d-e0ea-4de9-8a71-16c29178083f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train steps: (321, 10)\n",
            "Val steps: (69, 2)\n"
          ]
        }
      ],
      "source": [
        "train_steps = train_flow.n // train_flow.batch_size\n",
        "validation_steps = val_flow.n // val_flow.batch_size\n",
        "test_steps = test_flow.n // test_flow.batch_size\n",
        "\n",
        "what_to_monitor = 'val_loss'\n",
        "validation_data = val_flow\n",
        "validation_steps = validation_steps\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor = what_to_monitor,\n",
        "    patience = 2,  # 3\n",
        "    mode = 'auto',\n",
        "    restore_best_weights = True\n",
        ")\n",
        "\n",
        "print(f'Train steps: {train_flow.n, train_steps}')\n",
        "print(f'Val steps: {val_flow.n, validation_steps}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEAZgqWi0_ub"
      },
      "source": [
        "## Fix bug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "id": "b-0My8Gy0_uc"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "id": "bk8EEH6H0_ud"
      },
      "outputs": [],
      "source": [
        "# class AlexNet(Sequential):\n",
        "#     def __init__(self, input_shape, num_classes):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n",
        "#                         padding= 'valid', activation= 'relu',\n",
        "#                         input_shape= input_shape,\n",
        "#                         kernel_initializer= 'he_normal'))\n",
        "#         self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "#                               padding= 'valid', data_format= None))\n",
        "\n",
        "#         self.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
        "#                         padding= 'same', activation= 'relu',\n",
        "#                         kernel_initializer= 'he_normal'))\n",
        "#         self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "#                               padding= 'valid', data_format= None)) \n",
        "\n",
        "#         self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
        "#                         padding= 'same', activation= 'relu',\n",
        "#                         kernel_initializer= 'he_normal'))\n",
        "\n",
        "#         self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
        "#                         padding= 'same', activation= 'relu',\n",
        "#                         kernel_initializer= 'he_normal'))\n",
        "\n",
        "#         self.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
        "#                         padding= 'same', activation= 'relu',\n",
        "#                         kernel_initializer= 'he_normal'))\n",
        "\n",
        "#         self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
        "#                               padding= 'valid', data_format= None))\n",
        "\n",
        "#         self.add(Flatten())\n",
        "#         self.add(Dense(4096, activation= 'relu'))\n",
        "#         self.add(Dense(4096, activation= 'relu'))\n",
        "#         self.add(Dense(1000, activation= 'relu'))\n",
        "#         self.add(Dense(num_classes, activation= 'softmax'))\n",
        "\n",
        "#         # self.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "#         #             loss='categorical_crossentropy',\n",
        "#         #             metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 328,
      "metadata": {
        "id": "DyiVLDV-0_uf"
      },
      "outputs": [],
      "source": [
        "# m = AlexNet((256, 256, 3), 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 329,
      "metadata": {
        "id": "_d2K0XWG0_ug"
      },
      "outputs": [],
      "source": [
        "# m.compile(\n",
        "#     optimizer = tf.keras.optimizers.SGD(learning_rate = 0.001),  # tf.keras.optimizers.Adam(learning_rate = 0.0001),  # tf.keras.optimizers.Adam(learning_rate = 0.01001), #  'adam',\n",
        "#     loss = 'sparse_categorical_crossentropy',  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "#     metrics = ['accuracy'] \n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 330,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "VYvlk-0I0_uh",
        "outputId": "5242567d-b68f-474e-897a-48e4311fe2d9"
      },
      "outputs": [],
      "source": [
        "# m.fit(\n",
        "#     train_flow,\n",
        "#     steps_per_epoch = train_steps,\n",
        "\n",
        "#     validation_data = validation_data,\n",
        "#     validation_steps = validation_steps,\n",
        "\n",
        "#     epochs = 50 #epoch_hyperparam  # DatasetParameters.epochs\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bnGCuV4uFk1"
      },
      "source": [
        "## Get_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "id": "_mOKgACxtpUY"
      },
      "outputs": [],
      "source": [
        "def get_empty_models():\n",
        "    res = {\n",
        "        'CNN': CNNModel(name = 'CNN'),\n",
        "        'VGG19': VGG19Model(name = 'VGG19'),\n",
        "        'VGG16': VGG16Model(name = 'VGG16'),\n",
        "        'BN': BNModel(name = 'BN_CNN'),\n",
        "        'Dropout': DropoutModel(name = 'Dropout'),\n",
        "        'AlexNet': AlexNetModel(name = 'AlexNet'),\n",
        "        'Inception': InceptionModel(name = 'Inception'),\n",
        "        'ResNet': ResNetModel(name = 'ResNet')\n",
        "    }\n",
        "    return res\n",
        "    \n",
        "def construct_utils(model_name):\n",
        "    return ModelUtils(\n",
        "\n",
        "        model_params_dict = dict(**model_params),\n",
        "\n",
        "        checkpoint_params_dict = dict(\n",
        "            filepath = f'{DataProps.checkpoint_path}{model_name}/',\n",
        "            **checkpoint_params\n",
        "        ),\n",
        "\n",
        "        train_params_dict = dict(\n",
        "            **train_params\n",
        "        )\n",
        "    )\n",
        "\n",
        "def get_models(model_names):\n",
        "    empty_models = get_empty_models()\n",
        "    empty_model_names = list(empty_models.keys())\n",
        "    res = {}\n",
        "\n",
        "    for name in model_names:\n",
        "        assert name in empty_model_names\n",
        "        model = empty_models[name]\n",
        "        utils = construct_utils(name)\n",
        "\n",
        "        res.update(\n",
        "            {\n",
        "                name: {\n",
        "                    'model': model,\n",
        "                    'utils': utils\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "id": "HXtgTpGFtpUZ"
      },
      "outputs": [],
      "source": [
        "train_params = dict(\n",
        "    train_flow = train_flow,\n",
        "    train_steps = train_steps,\n",
        "\n",
        "    val_flow = validation_data,\n",
        "    val_steps = validation_steps,\n",
        "\n",
        "    epochs = epoch_hyperparam  # DatasetParameters.epochs\n",
        ")\n",
        "\n",
        "model_params = dict(\n",
        "    optimizer =  tf.keras.optimizers.SGD(learning_rate = 0.001),  #  tf.keras.optimizers.Adam(learning_rate = 0.0001),  # tf.keras.optimizers.Adam(learning_rate = 0.01001), #  'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "    metrics = ['accuracy'] \n",
        ")\n",
        "\n",
        "checkpoint_params = dict(\n",
        "    save_freq = 'epoch',\n",
        "    save_weights_only = True,\n",
        "    save_best_only = False,\n",
        "    verbose = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "id": "AXoZOk-kbeFU"
      },
      "outputs": [],
      "source": [
        "models = get_models(names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "id": "OWyWV1iXbeFT"
      },
      "outputs": [],
      "source": [
        "if using_gpu:\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name != '/device:GPU:0':\n",
        "        print(\n",
        "            '\\n\\nThis error most likely means that this notebook is not '\n",
        "            'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "            'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "        raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pihTRQph6Ngl"
      },
      "source": [
        "## Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22sYCf0BQEjY",
        "outputId": "535dfd42-2baa-442d-b8b4-a8b125e4bd0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Printing summary of AlexNet\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_90 (Conv2D)           (None, 62, 62, 96)        34944     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 30, 30, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_91 (Conv2D)           (None, 30, 30, 256)       614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 14, 14, 384)       885120    \n",
            "_________________________________________________________________\n",
            "conv2d_93 (Conv2D)           (None, 14, 14, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_94 (Conv2D)           (None, 14, 14, 256)       884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 4096)              37752832  \n",
            "_________________________________________________________________\n",
            "dense_63 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 3)                 3003      \n",
            "=================================================================\n",
            "Total params: 62,381,347\n",
            "Trainable params: 62,381,347\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "for name in names:\n",
        "    print(f'\\nPrinting summary of {name}')\n",
        "    print_summary(models, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW1tYvXtbeFT"
      },
      "source": [
        "## Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {
        "id": "bIlXdgwabeFU"
      },
      "outputs": [],
      "source": [
        "def fit_models(models_dict):\n",
        "\n",
        "    histories = {}\n",
        "    for model_name, parameters in models_dict.items():\n",
        "        \n",
        "        print(f'\\nFitting {model_name}')\n",
        "        model = parameters['model']\n",
        "        utils = parameters['utils']\n",
        "        \n",
        "        model.construct_model()\n",
        "        model.compile_model(**utils.model_params_dict)\n",
        "\n",
        "        checkpoint = tf.keras.callbacks.ModelCheckpoint(**utils.checkpoint_params_dict)\n",
        "\n",
        "        callbacks = [\n",
        "            early_stop,\n",
        "            checkpoint,\n",
        "            model.epoch_time_callback\n",
        "        ]\n",
        "\n",
        "        if using_gpu:\n",
        "            print(f'Fitting with GPU')\n",
        "            with tf.device(device_name):\n",
        "                history = fit_(\n",
        "                    **utils.train_params_dict,\n",
        "                    model = model.model,\n",
        "                    callbacks = callbacks\n",
        "                )\n",
        "        else:\n",
        "            print(f'Fitting without GPU')\n",
        "            history = fit_(\n",
        "                **utils.train_params_dict,\n",
        "                model = model.model,\n",
        "                callbacks = callbacks\n",
        "            )\n",
        "        histories[model_name] = history  \n",
        "\n",
        "        if saving_models:\n",
        "            save_dir = f'{DataProps.models_path}{model.name}/'\n",
        "            \n",
        "            if not(isdir(save_dir)):\n",
        "                os.mkdir(save_dir)\n",
        "            assert os.path.isdir(save_dir) == True\n",
        "            \n",
        "            print(f'saving model to dir: {save_dir}')\n",
        "            model.save_model(\n",
        "                dir = save_dir\n",
        "            )\n",
        "\n",
        "    if saving_histories:\n",
        "        print(f'Saving histories to {DataProps.histories_path}')\n",
        "        save_histories(histories, DataProps.histories_path)\n",
        "\n",
        "    \n",
        "    if saving_train_times:\n",
        "        save_times_dir = DataProps.models_path + 'training_time.csv'\n",
        "        print(f'Saving training times to {save_times_dir}')\n",
        "        save_train_times(\n",
        "            models_dict = models,\n",
        "            save_dir = save_times_dir\n",
        "        )\n",
        "\n",
        "    return histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "WcUrfNzJbeFU",
        "outputId": "c2551943-758f-4037-d454-75d071b88472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fitting AlexNet\n",
            "Fitting without GPU\n",
            "ERROR:tensorflow:Couldn't match files for checkpoint C:/Users/79137/Pasha/2. UNIPD/HDA/Project/Checkpoints/2022-01-31/AlexNet\\.\n",
            "Epoch 1/500\n",
            " 9/10 [==========================>...] - ETA: 3s - loss: 1.5233 - acc: 0.3696\n",
            "Epoch 00001: saving model to C:/Users/79137/Pasha/2. UNIPD/HDA/Project/Checkpoints/2022-01-31/AlexNet/\n",
            "10/10 [==============================] - 41s 4s/step - loss: 1.4860 - acc: 0.3668 - val_loss: 1.0663 - val_acc: 0.3594\n",
            "Epoch 2/500\n",
            " 9/10 [==========================>...] - ETA: 3s - loss: 1.2003 - acc: 0.3658\n",
            "Epoch 00002: saving model to C:/Users/79137/Pasha/2. UNIPD/HDA/Project/Checkpoints/2022-01-31/AlexNet/\n",
            "10/10 [==============================] - 42s 4s/step - loss: 1.1821 - acc: 0.3841 - val_loss: 1.0511 - val_acc: 0.5781\n",
            "Epoch 3/500\n",
            " 9/10 [==========================>...] - ETA: 3s - loss: 1.0052 - acc: 0.5243\n",
            "Epoch 00003: saving model to C:/Users/79137/Pasha/2. UNIPD/HDA/Project/Checkpoints/2022-01-31/AlexNet/\n",
            "10/10 [==============================] - 40s 4s/step - loss: 1.0062 - acc: 0.5219 - val_loss: 0.9838 - val_acc: 0.4844\n",
            "Epoch 4/500\n",
            " 9/10 [==========================>...] - ETA: 3s - loss: 1.0551 - acc: 0.5136\n",
            "Epoch 00004: saving model to C:/Users/79137/Pasha/2. UNIPD/HDA/Project/Checkpoints/2022-01-31/AlexNet/\n",
            "10/10 [==============================] - 37s 4s/step - loss: 1.0560 - acc: 0.5017 - val_loss: 0.9370 - val_acc: 0.5781\n",
            "Epoch 5/500\n",
            " 9/10 [==========================>...] - ETA: 2s - loss: 1.0039 - acc: 0.5177\n",
            "Epoch 00005: saving model to C:/Users/79137/Pasha/2. UNIPD/HDA/Project/Checkpoints/2022-01-31/AlexNet/\n",
            "10/10 [==============================] - 30s 3s/step - loss: 1.0681 - acc: 0.4922 - val_loss: 1.0036 - val_acc: 0.4844\n",
            "Epoch 6/500\n",
            " 9/10 [==========================>...] - ETA: 2s - loss: 0.9845 - acc: 0.5069\n",
            "Epoch 00006: saving model to C:/Users/79137/Pasha/2. UNIPD/HDA/Project/Checkpoints/2022-01-31/AlexNet/\n",
            "10/10 [==============================] - 31s 3s/step - loss: 0.9796 - acc: 0.5188 - val_loss: 0.9177 - val_acc: 0.6250\n",
            "Epoch 7/500\n",
            " 9/10 [==========================>...] - ETA: 2s - loss: 0.9963 - acc: 0.5759\n",
            "Epoch 00007: saving model to C:/Users/79137/Pasha/2. UNIPD/HDA/Project/Checkpoints/2022-01-31/AlexNet/\n",
            "10/10 [==============================] - 29s 3s/step - loss: 0.9912 - acc: 0.5709 - val_loss: 0.8798 - val_acc: 0.7031\n",
            "Epoch 8/500\n",
            " 5/10 [==============>...............] - ETA: 8s - loss: 0.8709 - acc: 0.6667 "
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9980\\2620315080.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m histories = fit_models(\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodels_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m )\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9980\\3203908886.py\u001b[0m in \u001b[0;36mfit_models\u001b[1;34m(models_dict)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_params_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             )\n\u001b[0;32m     36\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\79137\\Pasha\\2. UNIPD\\HDA\\Project\\Code\\Covid19Classifier\\Utils.py\u001b[0m in \u001b[0;36mfit_\u001b[1;34m(model, train_flow, train_steps, val_flow, val_steps, epochs, callbacks)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m     )\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    674\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager_dataset_or_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m       \u001b[1;31m# Make sure that y, sample_weights, validation_split are not passed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m       \u001b[0mbatch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[1;34m(generator, mode)\u001b[0m\n\u001b[0;32m    360\u001b[0m   \u001b[1;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    777\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "histories = fit_models(\n",
        "    models_dict = models\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-GukL4IJvsz",
        "outputId": "df260732-c969-407c-9058-505bb7de57cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Inception': <keras.callbacks.History at 0x7f73fa0929d0>}"
            ]
          },
          "execution_count": 270,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ7N4rtPoQ7p",
        "outputId": "06d75ec2-94a9-422f-ce98-e81818161126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "276/276 [==============================] - 49s 180ms/step - loss: 1.4012 - accuracy: 0.3333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "if 'ResNet' in names:\n",
        "    m = collect_metrics(\n",
        "            {'ResNet': models['ResNet']['model']}, test_flow, test_steps\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIcHh1Lwi5TQ",
        "outputId": "29cfc143-513d-4d38-ab56-7a7d2e657bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69/69 [==============================] - 17s 254ms/step - loss: 1.0986 - accuracy: 0.3333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "if 'Inception' in names:\n",
        "    m = collect_metrics(\n",
        "            {'Inception': models['Inception']['model']}, test_flow, test_steps\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z44j222SB8t",
        "outputId": "16399cef-d398-4f53-9a51-2fb03c27aab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "681/681 [==============================] - 216s 318ms/step - loss: 0.7719 - acc: 0.8297\n"
          ]
        }
      ],
      "source": [
        "# To check if bugs\n",
        "if 'CNN' in names:\n",
        "    m = collect_metrics(\n",
        "        {'CNN': models['CNN']['model']}, test_flow, test_steps\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2enDTZdJvsz",
        "outputId": "900cbf06-23e1-4e0a-c1fe-08d522ebe2c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "138/138 [==============================] - 3s 21ms/step - loss: 0.6301 - acc: 0.6522\n"
          ]
        }
      ],
      "source": [
        "if 'Dropout' in names:\n",
        "    m = collect_metrics(\n",
        "            {'Dropout': models['Dropout']['model']}, test_flow, test_steps    \n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
