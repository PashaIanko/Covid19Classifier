{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bhoecUqzJvsh"
      },
      "outputs": [],
      "source": [
        "# MAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0ol4IvhsbeFA"
      },
      "outputs": [],
      "source": [
        "# MAIN\n",
        "\n",
        "env = 'colab'  # 'colab' or 'pc'\n",
        "\n",
        "using_gpu = True  # True or False\n",
        "\n",
        "percentage = 0.15 # 0.99\n",
        "epoch_hyperparam = 500  # I use early stop\n",
        "train_percentage = percentage  # how much of train set we will use\n",
        "val_percentage = percentage\n",
        "test_percentage = percentage\n",
        "\n",
        "saving_models = True\n",
        "saving_train_times = True\n",
        "saving_histories = True\n",
        "n_trial = 1\n",
        "\n",
        "names = ['VGG19']  # , 'CNN']\n",
        "git_download_path = 'https://raw.githubusercontent.com/PashaIanko/Covid19Classifier/main/'\n",
        "\n",
        "# Number of trial for this day (-> directory/24-01-22/trial-{n_trial}/ -- example of directories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfsyMy5yRWKF"
      },
      "source": [
        "# Packages & functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJq4oSfhRZY6",
        "outputId": "f72bcf6d-0f79-49c8-8c7e-95a529c3da04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "def download_files(url_dict):\n",
        "    for file, url in url_dict.items():\n",
        "        print(f'Downloading {file}')\n",
        "        !wget -O {file} {url} {file}\n",
        "\n",
        "\n",
        "if env == 'colab':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    \n",
        "    files = [\n",
        "            'DataProperties.py',\n",
        "            'DatasetParameters.py',\n",
        "            'Preprocessing.py',\n",
        "            'PreprocessingParameters.py',\n",
        "            \n",
        "            'Model.py',\n",
        "            'BNModel.py',\n",
        "            'CNNModel.py',\n",
        "            'VGG19Model.py',\n",
        "            'VGG16Model.py',\n",
        "            'AlexNetModel.py',\n",
        "            'DropoutModel.py',\n",
        "            'InceptionModel.py',\n",
        "            'ResNetModel.py',\n",
        "\n",
        "            'Utils.py',\n",
        "            'ModelUtils.py',\n",
        "            'TimeCallBack.py'\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2rAfLXFKykyQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[:3]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s6vCIMfcyq-N"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[3:6]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "r6-Rf7MUzBxU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "if env == 'colab':\n",
        "    url_dict = {file: git_download_path + file for file in files[6:]}\n",
        "    download_files(url_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F1ZGnrMJRY1b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c-oRA_bPUpOC"
      },
      "outputs": [],
      "source": [
        "# Models\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Conv2D as Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization as BatchNormalization\n",
        "from tensorflow.keras.layers import ReLU as ReLU\n",
        "from tensorflow.keras.layers import MaxPool2D as MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten as Flatten\n",
        "from tensorflow.keras.layers import Dense as Dense\n",
        "from tensorflow.keras.layers import Input as Input\n",
        "\n",
        "from os.path import isdir\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Plotting\n",
        "# import seaborn as sns\n",
        "\n",
        "# Utils\n",
        "import importlib\n",
        "from os.path import isdir\n",
        "# from datetime import date\n",
        "import pandas as pd\n",
        "\n",
        "# Dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EOLlI5vMp3zH"
      },
      "outputs": [],
      "source": [
        "import DataProperties \n",
        "import PreprocessingParameters \n",
        "import Preprocessing\n",
        "import DatasetParameters\n",
        "import Utils\n",
        "import CNNModel\n",
        "import BNModel\n",
        "import ResNetModel\n",
        "import DropoutModel\n",
        "import InceptionModel\n",
        "import AlexNetModel\n",
        "import VGG19Model\n",
        "import VGG16Model\n",
        "import Model\n",
        "import ModelUtils\n",
        "import TimeCallBack\n",
        "\n",
        "def reload_all(modules_list):\n",
        "    for module in modules_list:\n",
        "        importlib.reload(module)\n",
        "\n",
        "reload_all(\n",
        "    [\n",
        "        DataProperties,\n",
        "        PreprocessingParameters,\n",
        "        DatasetParameters,\n",
        "        Utils,\n",
        "        Preprocessing,\n",
        "\n",
        "        Model,\n",
        "        CNNModel,\n",
        "        BNModel,\n",
        "        DropoutModel,\n",
        "        \n",
        "        VGG16Model,\n",
        "        ResNetModel,\n",
        "        InceptionModel,\n",
        "        ModelUtils,\n",
        "        TimeCallBack,\n",
        "        VGG19Model,\n",
        "        AlexNetModel\n",
        "    ]\n",
        ")\n",
        "\n",
        "from DataProperties import DataProperties\n",
        "from PreprocessingParameters import PreprocessingParameters\n",
        "from DatasetParameters import DatasetParameters\n",
        "from Utils import *\n",
        "from Preprocessing import *\n",
        "from CNNModel import CNNModel\n",
        "from BNModel import BNModel\n",
        "from DropoutModel import DropoutModel\n",
        "from VGG19Model import VGG19Model\n",
        "from ResNetModel import ResNetModel\n",
        "from InceptionModel import InceptionModel\n",
        "from ModelUtils import ModelUtils\n",
        "from TimeCallBack import TimeCallBack\n",
        "from AlexNetModel import AlexNetModel\n",
        "from VGG16Model import VGG16Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "X7b1_VvlHYqm"
      },
      "outputs": [],
      "source": [
        "DataProps = DataProperties(\n",
        "    environment = env,\n",
        "    n_trial = n_trial\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdFefXHCRONl"
      },
      "source": [
        "# Class balance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYflDFndXpq0"
      },
      "source": [
        "## Paths download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yB4gIThHp3zR"
      },
      "outputs": [],
      "source": [
        "assert isdir(DataProps.train_data_path) == True\n",
        "assert isdir(DataProps.test_data_path) == True\n",
        "assert isdir(DataProps.val_data_path) == True\n",
        "assert isdir(DataProps.models_path) == True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "R5w0G9ffc3x8"
      },
      "outputs": [],
      "source": [
        "train_files = calc_files(directory = DataProps.train_data_path)\n",
        "train_covid_files = calc_files(DataProps.train_covid_path)\n",
        "train_pn_files = calc_files(DataProps.train_pneumonia_path)\n",
        "train_healthy_files = calc_files(DataProps.train_healthy_path)\n",
        "\n",
        "assert train_files == (train_covid_files + train_pn_files + train_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eiJ9GOvdc3x9"
      },
      "outputs": [],
      "source": [
        "val_files = calc_files(directory = DataProps.val_data_path)\n",
        "val_covid_files = calc_files(DataProps.val_covid_path)\n",
        "val_pn_files = calc_files(DataProps.val_pneumonia_path)\n",
        "val_healthy_files = calc_files(DataProps.val_healthy_path)\n",
        "\n",
        "assert val_files == (val_covid_files + val_pn_files + val_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0z-s2L9Hc3x9"
      },
      "outputs": [],
      "source": [
        "test_files = calc_files(DataProps.test_data_path)\n",
        "test_covid_files = calc_files(DataProps.test_covid_path)\n",
        "test_pn_files = calc_files(DataProps.test_pneumonia_path)\n",
        "test_healthy_files = calc_files(DataProps.test_healthy_path)\n",
        "\n",
        "assert test_files == (test_covid_files + test_pn_files + test_healthy_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "vd5khqHOc3x9",
        "outputId": "98225720-74fc-4eba-b22b-6b7df450b484"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'y')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "x = ['T', 'V', 'Test']\n",
        "y = [train_files, val_files, test_files]\n",
        "\n",
        "fig, ax = plt.subplots()    \n",
        "width = 0.75 # the width of the bars \n",
        "ax.bar(x, y, width, color=\"blue\")\n",
        "plt.title('Data split')\n",
        "plt.xlabel('Data set')\n",
        "plt.ylabel('y') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6k8gAyybeFO",
        "outputId": "42c5c30a-4083-4581-f6df-d5ddfe928214"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1067, 1067, 1067)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "train_covid_files, train_healthy_files, train_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3FufZoPbeFP",
        "outputId": "e433bef4-ead9-4092-9482-e3bed2ec56e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(229, 229, 229)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "val_covid_files, val_healthy_files, val_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1cbNyxfbeFP",
        "outputId": "56e840ea-976f-4fc9-f365-904534bd4738"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(229, 229, 229)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "test_covid_files, test_healthy_files, test_pn_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jGO38VQbeFP",
        "outputId": "cbb679a2-148f-4a35-cd96-d58ffa2cc33d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4575"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "train_files + val_files + test_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMTsTfy9dOH1"
      },
      "source": [
        "# Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJYeLGFxc_8h",
        "outputId": "0836e0af-4ad7-46d3-c774-e19cdc43f270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target shape is (224, 224)\n"
          ]
        }
      ],
      "source": [
        "# Each model requires special input size -> need to check\n",
        "input_sizes = {\n",
        "    'VGG16': (224, 224),\n",
        "    'VGG19': (224, 224),\n",
        "    'AlexNet': (256, 256)\n",
        "}\n",
        "\n",
        "assert len(names) == 1\n",
        "if names[0] in list(input_sizes.keys()):\n",
        "    target_shape = input_sizes[names[0]]\n",
        "else:\n",
        "    target_shape = PreprocessingParameters.target_shape\n",
        "\n",
        "print(f'Target shape is {target_shape}')\n",
        "\n",
        "if names[0] == 'VGG16' or names[0] == 'VGG19':\n",
        "    assert target_shape == (224, 224)\n",
        "if names[0] == 'AlexNet':\n",
        "    assert target_shape == (256, 256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD-sJtpibeFQ"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lSWgMs-p3zo",
        "outputId": "6354641a-1456-4210-9464-5a99389b96a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 483 images belonging to 3 classes.\n",
            "Use 483 images for train\n"
          ]
        }
      ],
      "source": [
        "train_generator = ImageDataGenerator(\n",
        "    # we use only a portion for train data (initially, to check if all works fine)\n",
        "    validation_split = 1 - train_percentage,  \n",
        "\n",
        "    # preprocessing\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    samplewise_center = DatasetParameters.samplewise_center,\n",
        "    featurewise_center = DatasetParameters.featurewise_center,\n",
        "    \n",
        "    # augmentation\n",
        "    width_shift_range = DatasetParameters.width_shift_range,\n",
        "    height_shift_range = DatasetParameters.height_shift_range,\n",
        "    rotation_range = DatasetParameters.rotation_range,\n",
        "    horizontal_flip = DatasetParameters.horizontal_flip,\n",
        "    vertical_flip = DatasetParameters.vertical_flip,\n",
        "    # brightness_range = [0.8, 1.0],\n",
        "    zoom_range = DatasetParameters.zoom_range\n",
        ")\n",
        "\n",
        "train_flow = train_generator.flow_from_directory(\n",
        "    directory = DataProps.train_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',  # 1D integer labels\n",
        "    batch_size = DatasetParameters.batch_size,\n",
        "    subset = 'training',\n",
        "    shuffle = DatasetParameters.shuffle_train,\n",
        "    seed = DatasetParameters.seed\n",
        ")\n",
        "print(f'Use {train_flow.n} images for train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW_Up6bkbeFR"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n98o85Jgc3x-",
        "outputId": "ab05b4ca-3db2-4350-eb91-36ffc6d177a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 105 images belonging to 3 classes.\n",
            "Use 105 images for validation\n"
          ]
        }
      ],
      "source": [
        "val_generator = ImageDataGenerator(\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    validation_split = 1 - val_percentage\n",
        ")\n",
        "\n",
        "val_flow = train_generator.flow_from_directory(\n",
        "    directory = DataProps.val_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',  # 1D integer labels\n",
        "    batch_size = DatasetParameters.batch_size,\n",
        "    subset = 'training',  # yes, training - we use val_split of data \n",
        "    shuffle = DatasetParameters.shuffle_validation,\n",
        "    seed = DatasetParameters.seed\n",
        ")\n",
        "\n",
        "print(f'Use {val_flow.n} images for validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwXEti7RbeFR"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aESoE1FWp3zr",
        "outputId": "0c30c431-29a6-4f62-d8af-3812f8581cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 105 images belonging to 3 classes.\n",
            "Use 105 images for test\n"
          ]
        }
      ],
      "source": [
        "test_generator = ImageDataGenerator(\n",
        "    preprocessing_function = Preprocessing.preprocess,\n",
        "    validation_split = 1 - test_percentage\n",
        ")\n",
        "\n",
        "test_flow = test_generator.flow_from_directory(\n",
        "    directory = DataProps.test_data_path,\n",
        "    target_size = target_shape,  # PreprocessingParameters.target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    classes = DataProperties.classes,\n",
        "    class_mode = 'sparse',\n",
        "    shuffle = DatasetParameters.shuffle_test,\n",
        "    seed = DatasetParameters.seed,\n",
        "    batch_size = 1,\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "print(f'Use {test_flow.n} images for test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gYAlvCLVp3zt"
      },
      "outputs": [],
      "source": [
        "assert train_flow.class_indices == test_flow.class_indices\n",
        "assert train_flow.class_indices == val_flow.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3WuMFeiabhG"
      },
      "source": [
        "# Visualizing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "xWs7ZSKVp3zu"
      },
      "outputs": [],
      "source": [
        "# how_many_to_show = 9\n",
        "# flow = train_flow\n",
        "# for _ in range(1):\n",
        "#     batch, labels = flow.next()\n",
        "#     print(batch.shape, np.max(batch))\n",
        "#     assert np.max(batch) <= 1.01\n",
        "#     assert np.min(batch) >= 0.0\n",
        "    \n",
        "#     visualize(\n",
        "#         batch, \n",
        "#         labels, \n",
        "#         how_many_to_show, \n",
        "#         class_indices = flow.class_indices,\n",
        "#         figsize=(10, 10)\n",
        "#     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOqcasA-beFS"
      },
      "source": [
        "# Fitting models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgxk5YIzbeFT"
      },
      "source": [
        "## Prepare steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61IBSOH_beFT",
        "outputId": "353e3256-fbdd-494b-90e1-7ffcaad753d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train steps: (483, 15)\n",
            "Val steps: (105, 3)\n"
          ]
        }
      ],
      "source": [
        "train_steps = train_flow.n // train_flow.batch_size\n",
        "validation_steps = val_flow.n // val_flow.batch_size\n",
        "test_steps = test_flow.n // test_flow.batch_size\n",
        "\n",
        "what_to_monitor = 'val_loss'\n",
        "validation_data = val_flow\n",
        "validation_steps = validation_steps\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor = what_to_monitor,\n",
        "    patience = 2,  # 3\n",
        "    mode = 'auto',\n",
        "    restore_best_weights = True,\n",
        "    min_delta = 0.0007\n",
        ")\n",
        "\n",
        "print(f'Train steps: {train_flow.n, train_steps}')\n",
        "print(f'Val steps: {val_flow.n, validation_steps}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dHNeeNkgehs"
      },
      "source": [
        "## FIXING BUG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QUdE7eZ0gehs"
      },
      "outputs": [],
      "source": [
        "# model = tf.keras.models.Sequential()\n",
        "# model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "# model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "# model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(units=4096,activation=\"relu\"))\n",
        "# model.add(Dense(units=4096,activation=\"relu\"))\n",
        "# model.add(Dense(units=3, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ozUQ_myygehs"
      },
      "outputs": [],
      "source": [
        "# model.compile(\n",
        "#     optimizer =  tf.keras.optimizers.Adam(learning_rate = 0.0001), #  tf.keras.optimizers.Adam(learning_rate = 0.001),  #  tf.keras.optimizers.Adam(learning_rate = 0.0001),  # tf.keras.optimizers.Adam(learning_rate = 0.01001), #  'adam',\n",
        "#     loss = 'sparse_categorical_crossentropy',  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "#     metrics = ['accuracy'] \n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "QzOmhL7Vgehs"
      },
      "outputs": [],
      "source": [
        "# model.fit(\n",
        "#     train_flow,\n",
        "#     steps_per_epoch = train_steps,\n",
        "#     validation_data = val_flow,\n",
        "#     validation_steps = validation_steps,\n",
        "#     epochs = 50\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "x1RWfdtzn91w"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size = (3,3), padding = 'same', activation = 'relu', input_shape = (224, 224, 3), kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(128, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(128, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(256, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(256, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(256, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(256, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.Conv2D(512, kernel_size = (3,3), padding = 'same', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(4096, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(4096, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(3, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "P1DkT1f5n91w"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer =  tf.keras.optimizers.Adam(learning_rate = 0.0001), #  tf.keras.optimizers.Adam(learning_rate = 0.001),  #  tf.keras.optimizers.Adam(learning_rate = 0.0001),  # tf.keras.optimizers.Adam(learning_rate = 0.01001), #  'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "    metrics = ['accuracy'] \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "aJquwPDun91x",
        "outputId": "38b0cc03-2e03-46bf-b129-3c41cc1a1bf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 146s 8s/step - loss: 1.9029 - accuracy: 0.3370 - val_loss: 1.0982 - val_accuracy: 0.2708\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 29s 2s/step - loss: 1.0925 - accuracy: 0.3858 - val_loss: 1.0376 - val_accuracy: 0.6771\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 28s 2s/step - loss: 0.9657 - accuracy: 0.5277 - val_loss: 0.6839 - val_accuracy: 0.6771\n",
            "Epoch 4/50\n",
            " 9/15 [=================>............] - ETA: 9s - loss: 0.8141 - accuracy: 0.5799 "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-2aab0e59971e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_flow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(\n",
        "    train_flow,\n",
        "    steps_per_epoch = train_steps,\n",
        "    validation_data = val_flow,\n",
        "    validation_steps = validation_steps,\n",
        "    epochs = 50\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bnGCuV4uFk1"
      },
      "source": [
        "## Get_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mOKgACxtpUY"
      },
      "outputs": [],
      "source": [
        "def get_empty_models():\n",
        "    res = {\n",
        "        'CNN': CNNModel(name = 'CNN'),\n",
        "        'VGG19': VGG19Model(name = 'VGG19'),\n",
        "        'VGG16': VGG16Model(name = 'VGG16'),\n",
        "        'BN': BNModel(name = 'BN_CNN'),\n",
        "        'Dropout': DropoutModel(name = 'Dropout'),\n",
        "        'AlexNet': AlexNetModel(name = 'AlexNet'),\n",
        "        'Inception': InceptionModel(name = 'Inception'),\n",
        "        'ResNet': ResNetModel(name = 'ResNet')\n",
        "    }\n",
        "    return res\n",
        "    \n",
        "def construct_utils(model_name):\n",
        "    return ModelUtils(\n",
        "\n",
        "        model_params_dict = dict(**model_params),\n",
        "\n",
        "        checkpoint_params_dict = dict(\n",
        "            filepath = f'{DataProps.checkpoint_path}{model_name}/',\n",
        "            **checkpoint_params\n",
        "        ),\n",
        "\n",
        "        train_params_dict = dict(\n",
        "            **train_params\n",
        "        )\n",
        "    )\n",
        "\n",
        "def get_models(model_names):\n",
        "    empty_models = get_empty_models()\n",
        "    empty_model_names = list(empty_models.keys())\n",
        "    res = {}\n",
        "\n",
        "    for name in model_names:\n",
        "        assert name in empty_model_names\n",
        "        model = empty_models[name]\n",
        "        utils = construct_utils(name)\n",
        "\n",
        "        res.update(\n",
        "            {\n",
        "                name: {\n",
        "                    'model': model,\n",
        "                    'utils': utils\n",
        "                }\n",
        "            }\n",
        "        )\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXtgTpGFtpUZ"
      },
      "outputs": [],
      "source": [
        "train_params = dict(\n",
        "    train_flow = train_flow,\n",
        "    train_steps = train_steps,\n",
        "\n",
        "    val_flow = validation_data,\n",
        "    val_steps = validation_steps,\n",
        "\n",
        "    epochs = epoch_hyperparam  # DatasetParameters.epochs\n",
        ")\n",
        "\n",
        "model_params = dict(\n",
        "    optimizer =  tf.keras.optimizers.SGD(learning_rate = 0.0001), #  tf.keras.optimizers.SGD(learning_rate = 0.001),  #  tf.keras.optimizers.Adam(learning_rate = 0.0001),  # tf.keras.optimizers.Adam(learning_rate = 0.01001), #  'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',  # tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
        "    metrics = ['acc'] \n",
        ")\n",
        "\n",
        "checkpoint_params = dict(\n",
        "    save_freq = 'epoch',\n",
        "    save_weights_only = True,\n",
        "    save_best_only = False,\n",
        "    verbose = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXoZOk-kbeFU"
      },
      "outputs": [],
      "source": [
        "models = get_models(names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWyWV1iXbeFT"
      },
      "outputs": [],
      "source": [
        "if using_gpu:\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name != '/device:GPU:0':\n",
        "        print(\n",
        "            '\\n\\nThis error most likely means that this notebook is not '\n",
        "            'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "            'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "        raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pihTRQph6Ngl"
      },
      "source": [
        "## Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22sYCf0BQEjY",
        "outputId": "64c8ec76-dd56-409c-f4d0-8921b143f894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Printing summary of VGG19\n",
            "WARNING:tensorflow:From C:\\Users\\79137\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 12291     \n",
            "=================================================================\n",
            "Total params: 139,582,531\n",
            "Trainable params: 139,582,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "for name in names:\n",
        "    print(f'\\nPrinting summary of {name}')\n",
        "    print_summary(models, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW1tYvXtbeFT"
      },
      "source": [
        "## Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIlXdgwabeFU"
      },
      "outputs": [],
      "source": [
        "def fit_models(models_dict):\n",
        "\n",
        "    histories = {}\n",
        "    for model_name, parameters in models_dict.items():\n",
        "        \n",
        "        print(f'\\nFitting {model_name}')\n",
        "        model = parameters['model']\n",
        "        utils = parameters['utils']\n",
        "        \n",
        "        model.construct_model()\n",
        "        model.compile_model(**utils.model_params_dict)\n",
        "\n",
        "        checkpoint = tf.keras.callbacks.ModelCheckpoint(**utils.checkpoint_params_dict)\n",
        "\n",
        "        callbacks = [\n",
        "            early_stop,\n",
        "            checkpoint,\n",
        "            model.epoch_time_callback\n",
        "        ]\n",
        "\n",
        "        if using_gpu:\n",
        "            print(f'Fitting with GPU')\n",
        "            with tf.device(device_name):\n",
        "                history = fit_(\n",
        "                    **utils.train_params_dict,\n",
        "                    model = model.model,\n",
        "                    callbacks = callbacks\n",
        "                )\n",
        "        else:\n",
        "            print(f'Fitting without GPU')\n",
        "            history = fit_(\n",
        "                **utils.train_params_dict,\n",
        "                model = model.model,\n",
        "                callbacks = callbacks\n",
        "            )\n",
        "        histories[model_name] = history  \n",
        "\n",
        "        if saving_models:\n",
        "            save_dir = f'{DataProps.models_path}{model.name}/'\n",
        "            \n",
        "            if not(isdir(save_dir)):\n",
        "                os.mkdir(save_dir)\n",
        "            assert os.path.isdir(save_dir) == True\n",
        "            \n",
        "            print(f'saving model to dir: {save_dir}')\n",
        "            model.save_model(\n",
        "                dir = save_dir\n",
        "            )\n",
        "\n",
        "    if saving_histories:\n",
        "        print(f'Saving histories to {DataProps.histories_path}')\n",
        "        save_histories(histories, DataProps.histories_path)\n",
        "\n",
        "    \n",
        "    if saving_train_times:\n",
        "        save_times_dir = DataProps.models_path + 'training_time.csv'\n",
        "        print(f'Saving training times to {save_times_dir}')\n",
        "        save_train_times(\n",
        "            models_dict = models,\n",
        "            save_dir = save_times_dir\n",
        "        )\n",
        "\n",
        "    return histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WcUrfNzJbeFU",
        "outputId": "9057c4ba-2765-4bfb-83c4-29c14b461caa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fitting VGG19\n",
            "Fitting without GPU\n",
            "Epoch 1/500\n",
            "7/8 [=========================>....] - ETA: 17s - loss: 1.0986 - acc: 0.3557\n",
            "Epoch 00001: saving model to C:/Users/79137/Pasha/2. UNIPD/HDA/Project/Checkpoints/2022-01-31/VGG19/\n",
            "8/8 [==============================] - 149s 19s/step - loss: 1.0986 - acc: 0.3673 - val_loss: 1.0986 - val_acc: 0.1875\n",
            "Epoch 2/500\n",
            "7/8 [=========================>....] - ETA: 17s - loss: 1.0986 - acc: 0.3557"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17420\\2620315080.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m histories = fit_models(\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodels_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m )\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17420\\3203908886.py\u001b[0m in \u001b[0;36mfit_models\u001b[1;34m(models_dict)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;33m**\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_params_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             )\n\u001b[0;32m     36\u001b[0m         \u001b[0mhistories\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\79137\\Pasha\\2. UNIPD\\HDA\\Project\\Code\\Covid19Classifier\\Utils.py\u001b[0m in \u001b[0;36mfit_\u001b[1;34m(model, train_flow, train_steps, val_flow, val_steps, epochs, callbacks)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m     )\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    674\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager_dataset_or_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m       \u001b[1;31m# Make sure that y, sample_weights, validation_split are not passed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "histories = fit_models(\n",
        "    models_dict = models\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-GukL4IJvsz",
        "outputId": "7608f219-4a9c-42ed-b5e0-f8691c6d1e11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'AlexNet': <keras.callbacks.History at 0x7ff9bc849550>}"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6NiJZcErVAP",
        "outputId": "b60820f8-e7a3-4ca3-acc3-8158218d584f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "681/681 [==============================] - 174s 256ms/step - loss: 0.4739 - acc: 0.8311\n"
          ]
        }
      ],
      "source": [
        "if 'VGG16' in names:\n",
        "    m = collect_metrics(\n",
        "        {'VGG': models['VGG16']['model']}, test_flow, test_steps\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LbFq2gVPaJD",
        "outputId": "136b194f-50be-4c74-9e0c-a6ce63e52771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "681/681 [==============================] - 161s 236ms/step - loss: 0.3934 - accuracy: 0.8767\n"
          ]
        }
      ],
      "source": [
        "if 'AlexNet' in names:\n",
        "    m = collect_metrics(\n",
        "        {'Alex': models['AlexNet']['model']}, test_flow, test_steps\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ7N4rtPoQ7p",
        "outputId": "06d75ec2-94a9-422f-ce98-e81818161126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "276/276 [==============================] - 49s 180ms/step - loss: 1.4012 - accuracy: 0.3333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "if 'ResNet' in names:\n",
        "    m = collect_metrics(\n",
        "            {'ResNet': models['ResNet']['model']}, test_flow, test_steps\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIcHh1Lwi5TQ",
        "outputId": "29cfc143-513d-4d38-ab56-7a7d2e657bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69/69 [==============================] - 17s 254ms/step - loss: 1.0986 - accuracy: 0.3333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "if 'Inception' in names:\n",
        "    m = collect_metrics(\n",
        "            {'Inception': models['Inception']['model']}, test_flow, test_steps\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z44j222SB8t",
        "outputId": "16399cef-d398-4f53-9a51-2fb03c27aab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "681/681 [==============================] - 216s 318ms/step - loss: 0.7719 - acc: 0.8297\n"
          ]
        }
      ],
      "source": [
        "# To check if bugs\n",
        "if 'CNN' in names:\n",
        "    m = collect_metrics(\n",
        "        {'CNN': models['CNN']['model']}, test_flow, test_steps\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2enDTZdJvsz",
        "outputId": "900cbf06-23e1-4e0a-c1fe-08d522ebe2c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "138/138 [==============================] - 3s 21ms/step - loss: 0.6301 - acc: 0.6522\n"
          ]
        }
      ],
      "source": [
        "if 'Dropout' in names:\n",
        "    m = collect_metrics(\n",
        "            {'Dropout': models['Dropout']['model']}, test_flow, test_steps    \n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}